{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ykhsMAsUtgAn",
        "outputId": "e23c4948-3432-46db-9ddc-c7aed207a3f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hellp Jupiter!\n"
          ]
        }
      ],
      "source": [
        "##===========##\n",
        "##  Imports  ##\n",
        "##===========##\n",
        "\n",
        "tom = 5\n",
        "\n",
        "print(\"Hellp Jupiter!\")\n",
        "\n",
        "print(\"Yo\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m38hulsgtj4C"
      },
      "outputs": [],
      "source": [
        "##====================================##\n",
        "##  Config (no hard-coded variables)  ##\n",
        "##====================================##\n",
        "\n",
        "config = {\n",
        "    \"general\" : {\n",
        "        \"base_seed\"  : -1,\n",
        "        \"board_size\" : 5,\n",
        "    },\n",
        "    \"data\" : {\n",
        "        \"input_fname\"      : \"combinationsSmallyyy.csv\",\n",
        "    },\n",
        "    \"model\" : {\n",
        "        \"ndim\"              : 128,\n",
        "        \"encoder_depth\"     : 4,\n",
        "        \"encoder_num_heads\" : 8,\n",
        "        \"encoder_do_MLP\"    : True,\n",
        "        \"decoder_depth\"     : 4,\n",
        "        \"decoder_num_heads\" : 8,\n",
        "        \"decoder_do_MLP\"    : True,\n",
        "        \"MLP_depth\"         : 3,\n",
        "        \"use_bias\"          : True,\n",
        "        \"learning_rate\"     : 1e-5,\n",
        "    },\n",
        "    \"training\" : {\n",
        "        \"epochs\"           : 500,\n",
        "        \"batch_size\"       : 32,\n",
        "        \"patience\"         : 20,\n",
        "        \"validation_split\" : 0.2,\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMCsHmRSuEJG",
        "outputId": "8ce512b0-ef89-4a49-d94e-d5e5b94281c0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'logging' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\tomqu\\Dropbox\\ALL TQ Finance\\University of Manchester\\GBI\\GBIFormer4by4 - Copy.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4%20-%20Copy.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m##=====================##\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4%20-%20Copy.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m##  Configure logging  ##\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4%20-%20Copy.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m##=====================##\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4%20-%20Copy.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4%20-%20Copy.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m##  Get named logger\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4%20-%20Copy.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mgetLogger(\u001b[39m__name__\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4%20-%20Copy.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m##  Add output handler to stdout\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4%20-%20Copy.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m io_handler \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mStreamHandler(sys\u001b[39m.\u001b[39mstdout)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'logging' is not defined"
          ]
        }
      ],
      "source": [
        "##=====================##\n",
        "##  Configure logging  ##\n",
        "##=====================##\n",
        "\n",
        "##  Get named logger\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "##  Add output handler to stdout\n",
        "io_handler = logging.StreamHandler(sys.stdout)\n",
        "io_handler.setFormatter(logging.Formatter(\"%(levelname)7s %(asctime)s: %(message)s\", \"%Y-%m-%d %H:%M:%S\"))\n",
        "io_handler.setLevel(logging.INFO)\n",
        "logger.setLevel(logging.INFO)\n",
        "logger.addHandler(io_handler)\n",
        "\n",
        "##  Test that we see output\n",
        "logger.info(f\"Configured for logger '{logger.name}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHD7uOeRuJT2",
        "outputId": "1045213c-da9d-4b81-90b4-dd959c746dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:34:19: ---------------+-----------------------------------------------------------\n",
            "   INFO 2023-11-28 10:34:19:       Package  | Version\n",
            "   INFO 2023-11-28 10:34:19: ---------------+-----------------------------------------------------------\n",
            "   INFO 2023-11-28 10:34:19:        Python  |  3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]\n",
            "   INFO 2023-11-28 10:34:19:    Matplotlib  |  3.5.1\n",
            "   INFO 2023-11-28 10:34:19:         Numpy  |  1.22.0\n",
            "   INFO 2023-11-28 10:34:19:        Pandas  |  1.3.5\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\tomqu\\Dropbox\\ALL TQ Finance\\University of Manchester\\GBI\\GBIFormer4by4.ipynb Cell 4\u001b[0m line \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m        Numpy  |  \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39m__version__\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m       Pandas  |  \u001b[39m\u001b[39m{\u001b[39;00mpd\u001b[39m.\u001b[39m__version__\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4.ipynb#W4sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m   Tensorflow  |  \u001b[39m\u001b[39m{\u001b[39;00mtf\u001b[39m.\u001b[39m__version__\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "##======================================##\n",
        "##  Print versions for reproducibility  ##\n",
        "##======================================##\n",
        "\n",
        "logger.info( \"---------------+-----------------------------------------------------------\")\n",
        "logger.info( \"      Package  | Version\")\n",
        "logger.info( \"---------------+-----------------------------------------------------------\")\n",
        "logger.info(f\"       Python  |  {sys.version}\")\n",
        "logger.info(f\"   Matplotlib  |  {mpl.__version__}\")\n",
        "logger.info(f\"        Numpy  |  {np.__version__}\")\n",
        "logger.info(f\"       Pandas  |  {pd.__version__}\")\n",
        "logger.info(f\"   Tensorflow  |  {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Xql19xmuNR2",
        "outputId": "dd3184a3-48d0-4890-fa13-0e6d5cca025e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:34:39: Using the following config values:\n",
            "   INFO 2023-11-28 10:34:39:  > general > base_seed : -1\n",
            "   INFO 2023-11-28 10:34:39:  > general > board_size : 5\n",
            "   INFO 2023-11-28 10:34:39:  > data > input_fname : combinationsSmallyyy.csv\n",
            "   INFO 2023-11-28 10:34:39:  > model > ndim : 128\n",
            "   INFO 2023-11-28 10:34:39:  > model > encoder_depth : 4\n",
            "   INFO 2023-11-28 10:34:39:  > model > encoder_num_heads : 8\n",
            "   INFO 2023-11-28 10:34:39:  > model > encoder_do_MLP : True\n",
            "   INFO 2023-11-28 10:34:39:  > model > decoder_depth : 4\n",
            "   INFO 2023-11-28 10:34:39:  > model > decoder_num_heads : 8\n",
            "   INFO 2023-11-28 10:34:39:  > model > decoder_do_MLP : True\n",
            "   INFO 2023-11-28 10:34:39:  > model > MLP_depth : 3\n",
            "   INFO 2023-11-28 10:34:39:  > model > use_bias : True\n",
            "   INFO 2023-11-28 10:34:39:  > model > learning_rate : 1e-05\n",
            "   INFO 2023-11-28 10:34:39:  > training > epochs : 500\n",
            "   INFO 2023-11-28 10:34:39:  > training > batch_size : 32\n",
            "   INFO 2023-11-28 10:34:39:  > training > patience : 20\n",
            "   INFO 2023-11-28 10:34:39:  > training > validation_split : 0.2\n"
          ]
        }
      ],
      "source": [
        "##==============##\n",
        "##  Log config  ##\n",
        "##==============##\n",
        "\n",
        "def log_flattened_dictionary(logger     : logging.Logger,\n",
        "                             dictionary : dict,\n",
        "                             base_str   : str = \"\",\n",
        "                             log_lvl    : int = logging.INFO,\n",
        "                            ) -> None :\n",
        "    \"\"\"\n",
        "    Recursively search through config dictionary provided and log all values found\n",
        "    Dictionary keys must be castable to str\n",
        "    \"\"\"\n",
        "    for key, val in dictionary.items() :\n",
        "        if isinstance(val, dict) :\n",
        "            log_flattened_dictionary(logger, val, base_str=f\"{base_str} > {key}\")\n",
        "            continue\n",
        "        logger.log(log_lvl, f\"{base_str} > {key} : {val}\")\n",
        "\n",
        "logger.info(\"Using the following config values:\")\n",
        "log_flattened_dictionary(logger, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUKIDceSuSrk",
        "outputId": "f4d5c8d1-fe51-4323-ec06-ddd27638b3b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:34:43: Setting base_seed = 1701167683\n",
            "   INFO 2023-11-28 10:34:43: Python seed = 1701167683\n",
            "   INFO 2023-11-28 10:34:43: Numpy seed = 1701167684\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'tf' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\tomqu\\Dropbox\\ALL TQ Finance\\University of Manchester\\GBI\\GBIFormer4by4.ipynb Cell 6\u001b[0m line \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4.ipynb#W6sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m##  Set tensorflow seed\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4.ipynb#W6sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m tf_seed \u001b[39m=\u001b[39m base_seed \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4.ipynb#W6sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mset_seed(tf_seed)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tomqu/Dropbox/ALL%20TQ%20Finance/University%20of%20Manchester/GBI/GBIFormer4by4.ipynb#W6sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTensorflow seed = \u001b[39m\u001b[39m{\u001b[39;00mtf_seed\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
          ]
        }
      ],
      "source": [
        "##==========================##\n",
        "##  Configure random seeds  ##\n",
        "##==========================##\n",
        "\n",
        "##  Get base seed\n",
        "base_seed = config[\"general\"][\"base_seed\"]\n",
        "\n",
        "##  If <1 then set to clock time in seconds\n",
        "if base_seed < 1 :\n",
        "    base_seed = int(time.time())\n",
        "    logger.info(f\"Setting base_seed = {base_seed}\")\n",
        "\n",
        "##  Set python seed\n",
        "python_seed = base_seed\n",
        "random.seed(python_seed)\n",
        "logger.info(f\"Python seed = {python_seed}\")\n",
        "\n",
        "##  Set numpy seed\n",
        "np_seed = base_seed + 1\n",
        "np.random.seed(np_seed)\n",
        "logger.info(f\"Numpy seed = {np_seed}\")\n",
        "\n",
        "##  Set tensorflow seed\n",
        "tf_seed = base_seed + 2\n",
        "tf.random.set_seed(tf_seed)\n",
        "logger.info(f\"Tensorflow seed = {tf_seed}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhhwsWUTuWfc",
        "outputId": "6aa62ede-6359-4ca0-c3d3-cbbac532ee01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:34:59: Reading data from file combinationsSmallyyy.csv\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:34:59: Dataframe create with length 6:\n",
            "    Barrier                        Trajectory\n",
            "0  ((0, 1))  [(0, 0), (1, 1), (0, 2), (0, 3)]\n",
            "1  ((0, 1))  [(0, 0), (1, 1), (0, 2), (0, 3)]\n",
            "2  ((0, 1))  [(0, 0), (1, 1), (0, 2), (0, 3)]\n",
            "3  ((0, 1))  [(0, 0), (1, 1), (0, 2), (0, 3)]\n",
            "4  ((0, 1))  [(0, 0), (1, 1), (0, 2), (0, 3)]\n",
            "5  ((0, 1))  [(0, 0), (1, 1), (0, 2), (0, 3)]\n"
          ]
        }
      ],
      "source": [
        "##===========================##\n",
        "##  Read input to dataframe  ##\n",
        "##===========================##\n",
        "\n",
        "##  Resolve filename\n",
        "input_fname = config[\"data\"][\"input_fname\"]\n",
        "logger.info(f\"Reading data from file {input_fname}\")\n",
        "\n",
        "##  Load file\n",
        "df = pd.read_csv(\n",
        "input_fname,\n",
        ")\n",
        "\n",
        "##  Fix column heading format\n",
        "df = df.T.reset_index().T.reset_index(drop=True)\n",
        "df = df.set_axis([\"Barrier\", \"Trajectory\"], axis=1)\n",
        "\n",
        "##  Log results\n",
        "logger.info(f\"Dataframe create with length {len(df)}:\\n{str(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdjTkAFLvxXW"
      },
      "outputs": [],
      "source": [
        "##=================================================##\n",
        "##  Pull barriers and trajectories from dataframe  ##\n",
        "##=================================================##\n",
        "\n",
        "barriers     = list(df.iloc[:,0].map(lambda x : np.array(ast.literal_eval(x), dtype=np.int8)))\n",
        "trajectories = list(df.iloc[:,1].map(lambda x : np.array(ast.literal_eval(x), dtype=np.int8)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHRF85C4v2Nb",
        "outputId": "61791e84-6c0f-43a7-8580-0c00535be4c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:04: Creating data arrays according to board_size=5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Creating data arrays according to board_size=5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Data X created with shape (6, 6, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Data X created with shape (6, 6, 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Row at index 0 is:\n",
            "[[6 6]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [7 7]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Row at index 0 is:\n",
            "[[6 6]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [7 7]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Row at index 1 is:\n",
            "[[6 6]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [7 7]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Row at index 1 is:\n",
            "[[6 6]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [7 7]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Row at index 2 is:\n",
            "[[6 6]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [7 7]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Row at index 2 is:\n",
            "[[6 6]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [7 7]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Row at index 3 is:\n",
            "[[6 6]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [7 7]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Row at index 3 is:\n",
            "[[6 6]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [7 7]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Row at index 4 is:\n",
            "[[6 6]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [7 7]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Row at index 4 is:\n",
            "[[6 6]\n",
            " [1 1]\n",
            " [2 2]\n",
            " [1 3]\n",
            " [1 4]\n",
            " [7 7]]\n"
          ]
        }
      ],
      "source": [
        "##==================##\n",
        "##  Create X array  ##\n",
        "##==================##\n",
        "\n",
        "##  Get board size\n",
        "board_size = config[\"general\"][\"board_size\"]\n",
        "logger.info(f\"Creating data arrays according to board_size={board_size}\")\n",
        "\n",
        "##  Create list of sequences with BEGIN and END tokens\n",
        "X = []\n",
        "BEG, END = np.array([[board_size+1, board_size+1]]), np.array([[board_size+2, board_size+2]])\n",
        "for x in trajectories :\n",
        "    if len(x.shape) == 1 :\n",
        "        x = x[None, :]\n",
        "    x = np.concatenate([BEG, x+1, END])\n",
        "    X.append(x)\n",
        "\n",
        "##  Pad sequences with MASK token and convert to square array\n",
        "max_x = max([len(x) for x in X])\n",
        "X     = np.array([np.pad(x, [[0, max_x - len(x)], [0, 0]]) for x in X])\n",
        "\n",
        "##  Log summary\n",
        "logger.info(f\"Data X created with shape {X.shape}\")\n",
        "\n",
        "##  Log a few datapoints\n",
        "for row_idx in range(min([5, len(X)])) :\n",
        "    logger.info(f\"Row at index {row_idx} is:\\n{X[row_idx]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyHKVAfGwBFG",
        "outputId": "8c4cc043-6bf0-4135-80a6-582ce34c46c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Data Y created with shape (6, 5, 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Data Y created with shape (6, 5, 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Row at index 0 is:\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Row at index 0 is:\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Row at index 1 is:\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Row at index 1 is:\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Row at index 2 is:\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Row at index 2 is:\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Row at index 3 is:\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Row at index 3 is:\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Row at index 4 is:\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Row at index 4 is:\n",
            "[[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "##==================##\n",
        "##  Create Y array  ##\n",
        "##==================##\n",
        "\n",
        "##  Create tensor of square arrays with 0 or 1 if there is a barrier\n",
        "Y = []\n",
        "for barrier in barriers :\n",
        "    if len(barrier.shape) == 1 :\n",
        "        barrier = barrier[None, :]\n",
        "    y = np.zeros((board_size, board_size))\n",
        "    for pixel in barrier :\n",
        "        y[pixel[0], pixel[1]] = 1\n",
        "    Y.append(y)\n",
        "Y = np.array(Y)\n",
        "\n",
        "##  Log summary\n",
        "logger.info(f\"Data Y created with shape {Y.shape}\")\n",
        "\n",
        "##  Log a few datapoints\n",
        "for row_idx in range(min([5, len(Y)])) :\n",
        "    logger.info(f\"Row at index {row_idx} is:\\n{Y[row_idx]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRvdUFF9wKpD"
      },
      "outputs": [],
      "source": [
        "##===================================================================##\n",
        "##  Define custom keras layer for enumerating an NxN grid of pixels  ##\n",
        "##===================================================================##\n",
        "\n",
        "class EnumerateGrid(tf.keras.layers.Layer) :\n",
        "\n",
        "    def __init__(self,\n",
        "                 xmax : int,\n",
        "                 ymax : int | None = None,\n",
        "                 **kwargs\n",
        "                ) :\n",
        "        \"\"\"\n",
        "        Keras layer that outputs two flat tensors enumerating the x and y pixel locations on a grid\n",
        "        Both output tensors have shape [B, xmax*ymax] where B is the batch dimension, evaluated at run-time\n",
        "        by matching with a data tensor provided in the layer call\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        if ymax is None :\n",
        "            ymax = xmax\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        X, Y      = np.meshgrid(np.arange(xmax), np.arange(ymax))\n",
        "        X, Y      = X.flatten(), Y.flatten()\n",
        "        self.X    = tf.constant(X[None, :], dtype=self.dtype)\n",
        "        self.Y    = tf.constant(Y[None, :], dtype=self.dtype)\n",
        "\n",
        "    def call(self,\n",
        "             x   : tf.Tensor,\n",
        "            ) :\n",
        "        \"\"\"\n",
        "        Create an output tensors with same batch dimension as input x\n",
        "        First output tensor enumerates x positions on a grid\n",
        "        Second output tensor enumerates y positions on a grid\n",
        "        Both tensors have shape [B, xmax*ymax]\n",
        "        \"\"\"\n",
        "        X = tf.tile(self.X, [tf.shape(x)[0], 1])\n",
        "        Y = tf.tile(self.Y, [tf.shape(x)[0], 1])\n",
        "        return X, Y\n",
        "\n",
        "    def get_config(self) :\n",
        "        \"\"\"\n",
        "        Create config dict, needed for saving model to file\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config[\"amax\"] = self.amax\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZ_PAFUzwSjC"
      },
      "outputs": [],
      "source": [
        "##==========================================================================##\n",
        "##  Define custom keras layer for slicing the right-most index of a tensor  ##\n",
        "##==========================================================================##\n",
        "\n",
        "class RightSlice(tf.keras.layers.Layer) :\n",
        "\n",
        "    def __init__(self,\n",
        "                 index       : int,\n",
        "                 expand_dims : bool = False,\n",
        "                 **kwargs\n",
        "                ) :\n",
        "        \"\"\"\n",
        "        Keras layer that slices a tensor along its right-most axis and returns the index provided\n",
        "        \"\"\"\n",
        "        super().__init__(**kwargs)\n",
        "        self.index       = index\n",
        "        self.expand_dims = expand_dims\n",
        "\n",
        "    def call(self,\n",
        "             x   : tf.Tensor,\n",
        "            ) :\n",
        "        \"\"\"\n",
        "        Slices x along its right-most axis and returns the index provided\n",
        "        Output tensor has one fewer dimensions than x unless expand_dims is set to True\n",
        "        \"\"\"\n",
        "        ##  Slice x\n",
        "        y = x[..., self.index]\n",
        "\n",
        "        ##  Expand dims\n",
        "        if self.expand_dims :\n",
        "            y = y[..., None]\n",
        "\n",
        "        ## Return\n",
        "        return y\n",
        "\n",
        "    def get_config(self) :\n",
        "        \"\"\"\n",
        "        Create config dict, needed for saving model to file\n",
        "        \"\"\"\n",
        "        config = super().get_config()\n",
        "        config[\"index\"      ] = self.index\n",
        "        config[\"expand_dims\"] = self.expand_dims\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLeWZqZswaKT"
      },
      "outputs": [],
      "source": [
        "##====================================================##\n",
        "##  Define method for creating our transformer model  ##\n",
        "##====================================================##\n",
        "\n",
        "def create_model(board_size        : int,\n",
        "                 name              : str      = \"Tomformer\",\n",
        "                 ndim              : int      = 64,\n",
        "                 encoder_depth     : int      = 3,\n",
        "                 encoder_num_heads : int      = 8,\n",
        "                 encoder_do_MLP    : bool     = True,\n",
        "                 decoder_depth     : int      = 3,\n",
        "                 decoder_num_heads : int      = 8,\n",
        "                 decoder_do_MLP    : bool     = True,\n",
        "                 MLP_depth         : int      = 2,\n",
        "                 use_bias          : bool     = True,\n",
        "                 dtype                        = tf.float32,\n",
        "                 dtype_in                     = tf.int8,\n",
        "                 learning_rate     : float    = 1e-4,\n",
        "                 loss              : str      = \"binary_crossentropy\",\n",
        "                ) -> tf.keras.models.Model :\n",
        "    \"\"\"\n",
        "    Create keras transformer model and compile with Adam optimiser\n",
        "    \"\"\"\n",
        "\n",
        "    ##  Log model creation\n",
        "    logger.info(f\"Creating transformer model '{name}' with the following settings:\")\n",
        "    logger.info(f\"          board_size: {board_size}\")\n",
        "    logger.info(f\"                ndim: {ndim}\")\n",
        "    logger.info(f\"       encoder_depth: {encoder_depth}\")\n",
        "    logger.info(f\"   encoder_num_heads: {encoder_num_heads}\")\n",
        "    logger.info(f\"      encoder_do_MLP: {encoder_do_MLP}\")\n",
        "    logger.info(f\"       decoder_depth: {decoder_depth}\")\n",
        "    logger.info(f\"   decoder_num_heads: {decoder_num_heads}\")\n",
        "    logger.info(f\"      decoder_do_MLP: {decoder_do_MLP}\")\n",
        "    logger.info(f\"           MLP_depth: {MLP_depth}\")\n",
        "    logger.info(f\"            use_bias: {use_bias}\")\n",
        "    logger.info(f\"               dtype: {dtype}\")\n",
        "    logger.info(f\"            dtype_in: {dtype_in}\")\n",
        "    logger.info(f\"        learning_rate: {learning_rate}\")\n",
        "    logger.info(f\"                 loss: {loss}\")\n",
        "\n",
        "    ##  Input layer, size [S, 2]\n",
        "    x_in = tf.keras.layers.Input(\n",
        "        shape = (None, 2),\n",
        "        dtype = dtype_in,\n",
        "        name  = f\"{name}_input\",\n",
        "    )\n",
        "\n",
        "    ##  Pull x-component from input\n",
        "    Vx_in = RightSlice(\n",
        "        name  = f\"{name}_slice_x\",\n",
        "        index = 0,\n",
        "    )(x_in)\n",
        "\n",
        "    ##  Embed x-component\n",
        "    Vx = tf.keras.layers.Embedding(\n",
        "        name       = f\"{name}_encoder_embed_x\",\n",
        "        input_dim  = board_size + 3,\n",
        "        output_dim = ndim,\n",
        "        mask_zero  = True,\n",
        "    )(Vx_in)\n",
        "\n",
        "    ##  Pull y-component from input\n",
        "    Vy_in = RightSlice(\n",
        "        name  = f\"{name}_slice_y\",\n",
        "        index = 0,\n",
        "    )(x_in)\n",
        "\n",
        "    ##  Embed y-component\n",
        "    Vy = tf.keras.layers.Embedding(\n",
        "        name       = f\"{name}_encoder_embed_y\",\n",
        "        input_dim  = board_size + 3,\n",
        "        output_dim = ndim,\n",
        "        mask_zero  = True,\n",
        "    )(Vy_in)\n",
        "\n",
        "    ##  Combine x and y embeddings by addition\n",
        "    x = tf.keras.layers.Add(\n",
        "        name = f\"{name}_encoder_combine_x_y\",\n",
        "    )([Vx, Vy])\n",
        "\n",
        "    ##  Loop over encoder blocks\n",
        "    for layer_idx in range(encoder_depth) :\n",
        "\n",
        "        ##  Normalise x\n",
        "        m = tf.keras.layers.LayerNormalization(\n",
        "            name  = f\"{name}_encoder_LN0_layer{layer_idx}\",\n",
        "            dtype = dtype,\n",
        "        )(x)\n",
        "\n",
        "        ##  Calculate self-attention\n",
        "        m = tf.keras.layers.MultiHeadAttention(\n",
        "            name      = f\"{name}_encoder_MHSA_layer{layer_idx}\",\n",
        "            num_heads = encoder_num_heads,\n",
        "            key_dim   = ndim,\n",
        "            use_bias  = use_bias,\n",
        "            dtype     = dtype,\n",
        "        )(m, m)\n",
        "\n",
        "        ##  Add back to residual stream\n",
        "        x = tf.keras.layers.Add(\n",
        "            name = f\"{name}_encoder_add0_layer{layer_idx}\",\n",
        "        )([x, m])\n",
        "\n",
        "        ##  If no MLP then continue loop\n",
        "        if not encoder_do_MLP : continue\n",
        "\n",
        "        ##  Normalise x\n",
        "        m = tf.keras.layers.LayerNormalization(\n",
        "            name  = f\"{name}_encoder_LN1_layer{layer_idx}\",\n",
        "            dtype = dtype,\n",
        "        )(x)\n",
        "\n",
        "        ##  Calculate feed-forward block\n",
        "        m = tf.keras.layers.Dense(\n",
        "            name       = f\"{name}_encoder_MLP0_layer{layer_idx}\",\n",
        "            units      = 4*ndim,\n",
        "            use_bias   = use_bias,\n",
        "            activation = \"relu\",\n",
        "            dtype      = dtype,\n",
        "        )(m)\n",
        "        m = tf.keras.layers.Dense(\n",
        "            name       = f\"{name}_encoder_MLP1_layer{layer_idx}\",\n",
        "            units      = ndim,\n",
        "            use_bias   = use_bias,\n",
        "            activation = \"linear\",\n",
        "            dtype      = dtype,\n",
        "        )(m)\n",
        "\n",
        "        ##  Add back to residual stream\n",
        "        x = tf.keras.layers.Add(\n",
        "            name = f\"{name}_encoder_add1_layer{layer_idx}\",\n",
        "        )([x, m])\n",
        "\n",
        "    ##  Normalise x\n",
        "    x = tf.keras.layers.LayerNormalization(\n",
        "        name  = f\"{name}_encoder_post_LN\",\n",
        "        dtype = dtype,\n",
        "    )(x)\n",
        "\n",
        "    ##  Enumerate grid of pixels x and y for decoder\n",
        "    Vx, Vy = EnumerateGrid(\n",
        "        name = f\"{name}_decoder_enum_grid\",\n",
        "        xmax = board_size,\n",
        "    )(x)\n",
        "\n",
        "    ##  Embed x-component\n",
        "    Vx = tf.keras.layers.Embedding(\n",
        "        name       = f\"{name}_decoder_embed_x\",\n",
        "        input_dim  = board_size,\n",
        "        output_dim = ndim,\n",
        "        mask_zero  = False,\n",
        "    )(Vx)\n",
        "\n",
        "    ##  Embed y-component\n",
        "    Vy = tf.keras.layers.Embedding(\n",
        "        name       = f\"{name}_decoder_embed_y\",\n",
        "        input_dim  = board_size,\n",
        "        output_dim = ndim,\n",
        "        mask_zero  = False,\n",
        "    )(Vy)\n",
        "\n",
        "    ##  Combine x and y embeddings by addition\n",
        "    y = tf.keras.layers.Add(\n",
        "        name = f\"{name}_decoder_combine_x_y\",\n",
        "    )([Vx, Vy])\n",
        "\n",
        "    ##  Loop over decoder blocks\n",
        "    for layer_idx in range(decoder_depth) :\n",
        "\n",
        "        ##  Normalise y\n",
        "        m = tf.keras.layers.LayerNormalization(\n",
        "            name  = f\"{name}_decoder_LN0_layer{layer_idx}\",\n",
        "            dtype = dtype,\n",
        "        )(y)\n",
        "\n",
        "        ##  Calculate cross-attention\n",
        "        m = tf.keras.layers.MultiHeadAttention(\n",
        "            name      = f\"{name}_decoder_MHCA_layer{layer_idx}\",\n",
        "            num_heads = decoder_num_heads,\n",
        "            key_dim   = ndim,\n",
        "            use_bias  = use_bias,\n",
        "            dtype     = dtype,\n",
        "        )(m, x)\n",
        "\n",
        "        ##  Add back to residual stream\n",
        "        y = tf.keras.layers.Add(\n",
        "            name = f\"{name}_decoder_add0_layer{layer_idx}\",\n",
        "        )([y, m])\n",
        "\n",
        "        ##  Normalise y\n",
        "        m = tf.keras.layers.LayerNormalization(\n",
        "            name  = f\"{name}_decoder_LN1_layer{layer_idx}\",\n",
        "            dtype = dtype,\n",
        "        )(y)\n",
        "\n",
        "        ##  Calculate self-attention\n",
        "        m = tf.keras.layers.MultiHeadAttention(\n",
        "            name      = f\"{name}_decoder_MHSA_layer{layer_idx}\",\n",
        "            num_heads = decoder_num_heads,\n",
        "            key_dim   = ndim,\n",
        "            use_bias  = use_bias,\n",
        "            dtype     = dtype,\n",
        "        )(m, m)\n",
        "\n",
        "        ##  Add back to residual stream\n",
        "        y = tf.keras.layers.Add(\n",
        "            name = f\"{name}_decoder_add1_layer{layer_idx}\",\n",
        "        )([y, m])\n",
        "\n",
        "        ##  If no MLP then continue loop\n",
        "        if not decoder_do_MLP : continue\n",
        "\n",
        "        ##  Normalise y\n",
        "        m = tf.keras.layers.LayerNormalization(\n",
        "            name  = f\"{name}_decoder_LN2_layer{layer_idx}\",\n",
        "            dtype = dtype,\n",
        "        )(y)\n",
        "\n",
        "        ##  Calculate feed-forward block\n",
        "        m = tf.keras.layers.Dense(\n",
        "            name       = f\"{name}_decoder_MLP0_layer{layer_idx}\",\n",
        "            units      = 4*ndim,\n",
        "            use_bias   = use_bias,\n",
        "            activation = \"relu\",\n",
        "            dtype      = dtype,\n",
        "        )(m)\n",
        "        m = tf.keras.layers.Dense(\n",
        "            name       = f\"{name}_decoder_MLP1_layer{layer_idx}\",\n",
        "            units      = ndim,\n",
        "            use_bias   = use_bias,\n",
        "            activation = \"linear\",\n",
        "            dtype      = dtype,\n",
        "        )(m)\n",
        "\n",
        "        ##  Add back to residual stream\n",
        "        y = tf.keras.layers.Add(\n",
        "            name = f\"{name}_decoder_add2_layer{layer_idx}\",\n",
        "        )([y, m])\n",
        "\n",
        "    ##  Loop over MLP layers\n",
        "    for layer_idx in range(MLP_depth) :\n",
        "\n",
        "        ##  Normalise y\n",
        "        y = tf.keras.layers.LayerNormalization(\n",
        "            name  = f\"{name}_MLP_LN_layer{layer_idx}\",\n",
        "            dtype = dtype,\n",
        "        )(y)\n",
        "\n",
        "        ##  Calculate feed-forward block\n",
        "        y = tf.keras.layers.Dense(\n",
        "            name       = f\"{name}_MLP_layer{layer_idx}\",\n",
        "            units      = 4*ndim,\n",
        "            use_bias   = use_bias,\n",
        "            activation = \"relu\",\n",
        "            dtype      = dtype,\n",
        "        )(y)\n",
        "\n",
        "    y = tf.keras.layers.Dense(\n",
        "        name       = f\"{name}_logits\",\n",
        "        units      = 1,\n",
        "        use_bias   = use_bias,\n",
        "        activation = \"sigmoid\",\n",
        "        dtype      = dtype,\n",
        "    )(y)\n",
        "\n",
        "    ##  Shape to map size\n",
        "    y = tf.keras.layers.Reshape(\n",
        "        name         = f\"{name}_output\",\n",
        "        target_shape = (board_size, board_size),\n",
        "        input_shape  = (board_size*board_size, 1),\n",
        "    )(y)\n",
        "\n",
        "    ##  Create model\n",
        "    model = tf.keras.models.Model(\n",
        "        x_in,\n",
        "        y,\n",
        "        name = name,\n",
        "    )\n",
        "\n",
        "    ##  Compile\n",
        "    model.compile(\n",
        "        loss      = loss,\n",
        "        metrics   = [\"accuracy\"],\n",
        "        optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate),\n",
        "    )\n",
        "\n",
        "    ##  Log created model\n",
        "    model.summary(print_fn=logger.info)\n",
        "\n",
        "    ##  Return model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgDkJI6KwpMT",
        "outputId": "4e27d173-da3f-412e-b8ea-0a3e04a6c6d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05: Creating transformer model 'Tomformer' with the following settings:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Creating transformer model 'Tomformer' with the following settings:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:           board_size: 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:          board_size: 5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:                 ndim: 128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                ndim: 128\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:        encoder_depth: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:       encoder_depth: 4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:    encoder_num_heads: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:   encoder_num_heads: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:       encoder_do_MLP: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:      encoder_do_MLP: True\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:        decoder_depth: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:       decoder_depth: 4\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:    decoder_num_heads: 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:   decoder_num_heads: 8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:       decoder_do_MLP: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:      decoder_do_MLP: True\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:            MLP_depth: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:           MLP_depth: 3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:             use_bias: True\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:            use_bias: True\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:                dtype: <dtype: 'float32'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:               dtype: <dtype: 'float32'>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:             dtype_in: <dtype: 'int8'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:            dtype_in: <dtype: 'int8'>\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:         learning_rate: 1e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:        learning_rate: 1e-05\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:05:                  loss: binary_crossentropy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                 loss: binary_crossentropy\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09: Model: \"Tomformer\"\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Model: \"Tomformer\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09: __________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Layer (type)                Output Shape                 Param #   Connected to                  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Layer (type)                Output Shape                 Param #   Connected to                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09: ==================================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:==================================================================================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_input (InputLaye  [(None, None, 2)]            0         []                            \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_input (InputLaye  [(None, None, 2)]            0         []                            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  r)                                                                                               \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r)                                                                                               \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_slice_x (RightSl  (None, None)                 0         ['Tomformer_input[0][0]']     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_slice_x (RightSl  (None, None)                 0         ['Tomformer_input[0][0]']     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  ice)                                                                                             \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: ice)                                                                                             \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_slice_y (RightSl  (None, None)                 0         ['Tomformer_input[0][0]']     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_slice_y (RightSl  (None, None)                 0         ['Tomformer_input[0][0]']     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  ice)                                                                                             \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: ice)                                                                                             \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_embed_x   (None, None, 128)            1024      ['Tomformer_slice_x[0][0]']   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_embed_x   (None, None, 128)            1024      ['Tomformer_slice_x[0][0]']   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  (Embedding)                                                                                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: (Embedding)                                                                                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_embed_y   (None, None, 128)            1024      ['Tomformer_slice_y[0][0]']   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_embed_y   (None, None, 128)            1024      ['Tomformer_slice_y[0][0]']   \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  (Embedding)                                                                                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: (Embedding)                                                                                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_combine_  (None, None, 128)            0         ['Tomformer_encoder_embed_x[0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_combine_  (None, None, 128)            0         ['Tomformer_encoder_embed_x[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  x_y (Add)                                                          [0]',                         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: x_y (Add)                                                          [0]',                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                      'Tomformer_encoder_embed_y[0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_embed_y[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                     [0]']                         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0]']                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_LN0_laye  (None, None, 128)            256       ['Tomformer_encoder_combine_x_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_LN0_laye  (None, None, 128)            256       ['Tomformer_encoder_combine_x_\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  r0 (LayerNormalization)                                            y[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r0 (LayerNormalization)                                            y[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_MHSA_lay  (None, None, 128)            527488    ['Tomformer_encoder_LN0_layer0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MHSA_lay  (None, None, 128)            527488    ['Tomformer_encoder_LN0_layer0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  er0 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                      'Tomformer_encoder_LN0_layer0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_LN0_layer0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                     [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_add0_lay  (None, None, 128)            0         ['Tomformer_encoder_combine_x_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_add0_lay  (None, None, 128)            0         ['Tomformer_encoder_combine_x_\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  er0 (Add)                                                          y[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (Add)                                                          y[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                      'Tomformer_encoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                     0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_LN1_laye  (None, None, 128)            256       ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_LN1_laye  (None, None, 128)            256       ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  r0 (LayerNormalization)                                            0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r0 (LayerNormalization)                                            0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_MLP0_lay  (None, None, 512)            66048     ['Tomformer_encoder_LN1_layer0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MLP0_lay  (None, None, 512)            66048     ['Tomformer_encoder_LN1_layer0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  er0 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_MLP1_lay  (None, None, 128)            65664     ['Tomformer_encoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MLP1_lay  (None, None, 128)            65664     ['Tomformer_encoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  er0 (Dense)                                                        0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (Dense)                                                        0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_add1_lay  (None, None, 128)            0         ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_add1_lay  (None, None, 128)            0         ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  er0 (Add)                                                          0[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (Add)                                                          0[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                      'Tomformer_encoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                     0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_LN0_laye  (None, None, 128)            256       ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_LN0_laye  (None, None, 128)            256       ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  r1 (LayerNormalization)                                            0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r1 (LayerNormalization)                                            0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_MHSA_lay  (None, None, 128)            527488    ['Tomformer_encoder_LN0_layer1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MHSA_lay  (None, None, 128)            527488    ['Tomformer_encoder_LN0_layer1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  er1 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                      'Tomformer_encoder_LN0_layer1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_LN0_layer1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                     [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_add0_lay  (None, None, 128)            0         ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_add0_lay  (None, None, 128)            0         ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  er1 (Add)                                                          0[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (Add)                                                          0[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                      'Tomformer_encoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                     1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_LN1_laye  (None, None, 128)            256       ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_LN1_laye  (None, None, 128)            256       ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  r1 (LayerNormalization)                                            1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r1 (LayerNormalization)                                            1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_MLP0_lay  (None, None, 512)            66048     ['Tomformer_encoder_LN1_layer1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MLP0_lay  (None, None, 512)            66048     ['Tomformer_encoder_LN1_layer1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  er1 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_MLP1_lay  (None, None, 128)            65664     ['Tomformer_encoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MLP1_lay  (None, None, 128)            65664     ['Tomformer_encoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  er1 (Dense)                                                        1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (Dense)                                                        1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_add1_lay  (None, None, 128)            0         ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_add1_lay  (None, None, 128)            0         ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  er1 (Add)                                                          1[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (Add)                                                          1[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                      'Tomformer_encoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                     1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_LN0_laye  (None, None, 128)            256       ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_LN0_laye  (None, None, 128)            256       ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  r2 (LayerNormalization)                                            1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r2 (LayerNormalization)                                            1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  Tomformer_encoder_MHSA_lay  (None, None, 128)            527488    ['Tomformer_encoder_LN0_layer2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MHSA_lay  (None, None, 128)            527488    ['Tomformer_encoder_LN0_layer2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:  er2 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:09:                                                                      'Tomformer_encoder_LN0_layer2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_LN0_layer2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_add0_lay  (None, None, 128)            0         ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_add0_lay  (None, None, 128)            0         ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er2 (Add)                                                          1[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (Add)                                                          1[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_encoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_LN1_laye  (None, None, 128)            256       ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_LN1_laye  (None, None, 128)            256       ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r2 (LayerNormalization)                                            2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r2 (LayerNormalization)                                            2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_MLP0_lay  (None, None, 512)            66048     ['Tomformer_encoder_LN1_layer2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MLP0_lay  (None, None, 512)            66048     ['Tomformer_encoder_LN1_layer2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er2 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_MLP1_lay  (None, None, 128)            65664     ['Tomformer_encoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MLP1_lay  (None, None, 128)            65664     ['Tomformer_encoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er2 (Dense)                                                        2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (Dense)                                                        2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_add1_lay  (None, None, 128)            0         ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_add1_lay  (None, None, 128)            0         ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er2 (Add)                                                          2[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (Add)                                                          2[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_encoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_LN0_laye  (None, None, 128)            256       ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_LN0_laye  (None, None, 128)            256       ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r3 (LayerNormalization)                                            2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r3 (LayerNormalization)                                            2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_MHSA_lay  (None, None, 128)            527488    ['Tomformer_encoder_LN0_layer3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MHSA_lay  (None, None, 128)            527488    ['Tomformer_encoder_LN0_layer3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_encoder_LN0_layer3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_LN0_layer3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_add0_lay  (None, None, 128)            0         ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_add0_lay  (None, None, 128)            0         ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (Add)                                                          2[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (Add)                                                          2[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_encoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_LN1_laye  (None, None, 128)            256       ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_LN1_laye  (None, None, 128)            256       ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r3 (LayerNormalization)                                            3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r3 (LayerNormalization)                                            3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_MLP0_lay  (None, None, 512)            66048     ['Tomformer_encoder_LN1_layer3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MLP0_lay  (None, None, 512)            66048     ['Tomformer_encoder_LN1_layer3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_MLP1_lay  (None, None, 128)            65664     ['Tomformer_encoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_MLP1_lay  (None, None, 128)            65664     ['Tomformer_encoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (Dense)                                                        3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (Dense)                                                        3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_add1_lay  (None, None, 128)            0         ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_add1_lay  (None, None, 128)            0         ['Tomformer_encoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (Add)                                                          3[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (Add)                                                          3[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_encoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_encoder_post_LN   (None, None, 128)            256       ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_encoder_post_LN   (None, None, 128)            256       ['Tomformer_encoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  (LayerNormalization)                                               3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: (LayerNormalization)                                               3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_enum_gri  ((None, 25),                 0         ['Tomformer_encoder_post_LN[0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_enum_gri  ((None, 25),                 0         ['Tomformer_encoder_post_LN[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  d (EnumerateGrid)            (None, 25))                           [0]']                         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: d (EnumerateGrid)            (None, 25))                           [0]']                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_embed_x   (None, 25, 128)              640       ['Tomformer_decoder_enum_grid[\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_embed_x   (None, 25, 128)              640       ['Tomformer_decoder_enum_grid[\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  (Embedding)                                                        0][0]']                       \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: (Embedding)                                                        0][0]']                       \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_embed_y   (None, 25, 128)              640       ['Tomformer_decoder_enum_grid[\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_embed_y   (None, 25, 128)              640       ['Tomformer_decoder_enum_grid[\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  (Embedding)                                                        0][1]']                       \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: (Embedding)                                                        0][1]']                       \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_combine_  (None, 25, 128)              0         ['Tomformer_decoder_embed_x[0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_combine_  (None, 25, 128)              0         ['Tomformer_decoder_embed_x[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  x_y (Add)                                                          [0]',                         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: x_y (Add)                                                          [0]',                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_embed_y[0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_embed_y[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     [0]']                         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0]']                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN0_laye  (None, 25, 128)              256       ['Tomformer_decoder_combine_x_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN0_laye  (None, 25, 128)              256       ['Tomformer_decoder_combine_x_\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r0 (LayerNormalization)                                            y[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r0 (LayerNormalization)                                            y[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MHCA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN0_layer0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MHCA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN0_layer0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er0 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_encoder_post_LN[0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_post_LN[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     [0]']                         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0]']                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add0_lay  (None, 25, 128)              0         ['Tomformer_decoder_combine_x_\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add0_lay  (None, 25, 128)              0         ['Tomformer_decoder_combine_x_\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er0 (Add)                                                          y[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (Add)                                                          y[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MHCA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MHCA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN1_laye  (None, 25, 128)              256       ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN1_laye  (None, 25, 128)              256       ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r0 (LayerNormalization)                                            0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r0 (LayerNormalization)                                            0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MHSA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN1_layer0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MHSA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN1_layer0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er0 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_LN1_layer0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_LN1_layer0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add1_lay  (None, 25, 128)              0         ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add1_lay  (None, 25, 128)              0         ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er0 (Add)                                                          0[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (Add)                                                          0[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN2_laye  (None, 25, 128)              256       ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN2_laye  (None, 25, 128)              256       ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r0 (LayerNormalization)                                            0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r0 (LayerNormalization)                                            0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MLP0_lay  (None, 25, 512)              66048     ['Tomformer_decoder_LN2_layer0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MLP0_lay  (None, 25, 512)              66048     ['Tomformer_decoder_LN2_layer0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er0 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MLP1_lay  (None, 25, 128)              65664     ['Tomformer_decoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MLP1_lay  (None, 25, 128)              65664     ['Tomformer_decoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er0 (Dense)                                                        0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (Dense)                                                        0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add2_lay  (None, 25, 128)              0         ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add2_lay  (None, 25, 128)              0         ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er0 (Add)                                                          0[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er0 (Add)                                                          0[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN0_laye  (None, 25, 128)              256       ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN0_laye  (None, 25, 128)              256       ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r1 (LayerNormalization)                                            0[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r1 (LayerNormalization)                                            0[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MHCA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN0_layer1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MHCA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN0_layer1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er1 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_encoder_post_LN[0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_post_LN[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     [0]']                         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0]']                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add0_lay  (None, 25, 128)              0         ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add0_lay  (None, 25, 128)              0         ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er1 (Add)                                                          0[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (Add)                                                          0[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MHCA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MHCA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN1_laye  (None, 25, 128)              256       ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN1_laye  (None, 25, 128)              256       ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r1 (LayerNormalization)                                            1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r1 (LayerNormalization)                                            1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MHSA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN1_layer1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MHSA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN1_layer1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er1 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_LN1_layer1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_LN1_layer1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add1_lay  (None, 25, 128)              0         ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add1_lay  (None, 25, 128)              0         ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er1 (Add)                                                          1[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (Add)                                                          1[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN2_laye  (None, 25, 128)              256       ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN2_laye  (None, 25, 128)              256       ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r1 (LayerNormalization)                                            1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r1 (LayerNormalization)                                            1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MLP0_lay  (None, 25, 512)              66048     ['Tomformer_decoder_LN2_layer1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MLP0_lay  (None, 25, 512)              66048     ['Tomformer_decoder_LN2_layer1\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er1 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MLP1_lay  (None, 25, 128)              65664     ['Tomformer_decoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MLP1_lay  (None, 25, 128)              65664     ['Tomformer_decoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er1 (Dense)                                                        1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (Dense)                                                        1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add2_lay  (None, 25, 128)              0         ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add2_lay  (None, 25, 128)              0         ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er1 (Add)                                                          1[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er1 (Add)                                                          1[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN0_laye  (None, 25, 128)              256       ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN0_laye  (None, 25, 128)              256       ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r2 (LayerNormalization)                                            1[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r2 (LayerNormalization)                                            1[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MHCA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN0_layer2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MHCA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN0_layer2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er2 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_encoder_post_LN[0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_post_LN[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     [0]']                         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0]']                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add0_lay  (None, 25, 128)              0         ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add0_lay  (None, 25, 128)              0         ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er2 (Add)                                                          1[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (Add)                                                          1[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MHCA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MHCA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN1_laye  (None, 25, 128)              256       ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN1_laye  (None, 25, 128)              256       ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r2 (LayerNormalization)                                            2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r2 (LayerNormalization)                                            2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MHSA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN1_layer2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MHSA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN1_layer2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er2 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_LN1_layer2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_LN1_layer2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add1_lay  (None, 25, 128)              0         ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add1_lay  (None, 25, 128)              0         ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er2 (Add)                                                          2[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (Add)                                                          2[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN2_laye  (None, 25, 128)              256       ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN2_laye  (None, 25, 128)              256       ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r2 (LayerNormalization)                                            2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r2 (LayerNormalization)                                            2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MLP0_lay  (None, 25, 512)              66048     ['Tomformer_decoder_LN2_layer2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MLP0_lay  (None, 25, 512)              66048     ['Tomformer_decoder_LN2_layer2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er2 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MLP1_lay  (None, 25, 128)              65664     ['Tomformer_decoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MLP1_lay  (None, 25, 128)              65664     ['Tomformer_decoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er2 (Dense)                                                        2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (Dense)                                                        2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add2_lay  (None, 25, 128)              0         ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add2_lay  (None, 25, 128)              0         ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er2 (Add)                                                          2[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er2 (Add)                                                          2[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN0_laye  (None, 25, 128)              256       ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN0_laye  (None, 25, 128)              256       ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r3 (LayerNormalization)                                            2[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r3 (LayerNormalization)                                            2[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MHCA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN0_layer3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MHCA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN0_layer3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_encoder_post_LN[0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_encoder_post_LN[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     [0]']                         \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0]']                         \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add0_lay  (None, 25, 128)              0         ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add0_lay  (None, 25, 128)              0         ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (Add)                                                          2[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (Add)                                                          2[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MHCA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MHCA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN1_laye  (None, 25, 128)              256       ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN1_laye  (None, 25, 128)              256       ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r3 (LayerNormalization)                                            3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r3 (LayerNormalization)                                            3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MHSA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN1_layer3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MHSA_lay  (None, 25, 128)              527488    ['Tomformer_decoder_LN1_layer3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (MultiHeadAttention)                                           [0][0]',                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_LN1_layer3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_LN1_layer3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add1_lay  (None, 25, 128)              0         ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add1_lay  (None, 25, 128)              0         ['Tomformer_decoder_add0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (Add)                                                          3[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (Add)                                                          3[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MHSA_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_LN2_laye  (None, 25, 128)              256       ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_LN2_laye  (None, 25, 128)              256       ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  r3 (LayerNormalization)                                            3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: r3 (LayerNormalization)                                            3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MLP0_lay  (None, 25, 512)              66048     ['Tomformer_decoder_LN2_layer3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MLP0_lay  (None, 25, 512)              66048     ['Tomformer_decoder_LN2_layer3\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (Dense)                                                        [0][0]']                      \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_MLP1_lay  (None, 25, 128)              65664     ['Tomformer_decoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_MLP1_lay  (None, 25, 128)              65664     ['Tomformer_decoder_MLP0_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (Dense)                                                        3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (Dense)                                                        3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_decoder_add2_lay  (None, 25, 128)              0         ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_decoder_add2_lay  (None, 25, 128)              0         ['Tomformer_decoder_add1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  er3 (Add)                                                          3[0][0]',                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: er3 (Add)                                                          3[0][0]',                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                      'Tomformer_decoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                     'Tomformer_decoder_MLP1_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                     3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                    3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_MLP_LN_layer0 (L  (None, 25, 128)              256       ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_MLP_LN_layer0 (L  (None, 25, 128)              256       ['Tomformer_decoder_add2_layer\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  ayerNormalization)                                                 3[0][0]']                     \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: ayerNormalization)                                                 3[0][0]']                     \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_MLP_layer0 (Dens  (None, 25, 512)              66048     ['Tomformer_MLP_LN_layer0[0][0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_MLP_layer0 (Dens  (None, 25, 512)              66048     ['Tomformer_MLP_LN_layer0[0][0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  e)                                                                 ]']                           \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: e)                                                                 ]']                           \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_MLP_LN_layer1 (L  (None, 25, 512)              1024      ['Tomformer_MLP_layer0[0][0]']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_MLP_LN_layer1 (L  (None, 25, 512)              1024      ['Tomformer_MLP_layer0[0][0]']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  ayerNormalization)                                                                               \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: ayerNormalization)                                                                               \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_MLP_layer1 (Dens  (None, 25, 512)              262656    ['Tomformer_MLP_LN_layer1[0][0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_MLP_layer1 (Dens  (None, 25, 512)              262656    ['Tomformer_MLP_LN_layer1[0][0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  e)                                                                 ]']                           \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: e)                                                                 ]']                           \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_MLP_LN_layer2 (L  (None, 25, 512)              1024      ['Tomformer_MLP_layer1[0][0]']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_MLP_LN_layer2 (L  (None, 25, 512)              1024      ['Tomformer_MLP_layer1[0][0]']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  ayerNormalization)                                                                               \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: ayerNormalization)                                                                               \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_MLP_layer2 (Dens  (None, 25, 512)              262656    ['Tomformer_MLP_LN_layer2[0][0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_MLP_layer2 (Dens  (None, 25, 512)              262656    ['Tomformer_MLP_LN_layer2[0][0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  e)                                                                 ]']                           \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: e)                                                                 ]']                           \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_logits (Dense)    (None, 25, 1)                513       ['Tomformer_MLP_layer2[0][0]']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_logits (Dense)    (None, 25, 1)                513       ['Tomformer_MLP_layer2[0][0]']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:  Tomformer_output (Reshape)  (None, 5, 5)                 0         ['Tomformer_logits[0][0]']    \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__: Tomformer_output (Reshape)  (None, 5, 5)                 0         ['Tomformer_logits[0][0]']    \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10:                                                                                                   \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:                                                                                                  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:10: ==================================================================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:==================================================================================================\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11: Total params: 7986433 (30.47 MB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Total params: 7986433 (30.47 MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11: Trainable params: 7986433 (30.47 MB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Trainable params: 7986433 (30.47 MB)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11: Non-trainable params: 0 (0.00 Byte)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Non-trainable params: 0 (0.00 Byte)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11: __________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "##==================================##\n",
        "##  Create transformer keras model  ##\n",
        "##==================================##\n",
        "\n",
        "model = create_model(\n",
        "    board_size = board_size,\n",
        "    **config[\"model\"],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xonJvXlIwxki",
        "outputId": "4c5c2ec2-315d-45ab-f8b1-e59536fcf39b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11: Validation split is 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Validation split is 0.2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11: Assigned following indicies for training data: [4 3 5 1 2]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Assigned following indicies for training data: [4 3 5 1 2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11: Assigned following indicies for validation data: [0]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Assigned following indicies for validation data: [0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11: train_X created with shape: (5, 6, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:train_X created with shape: (5, 6, 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11: train_Y created with shape: (5, 5, 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:train_Y created with shape: (5, 5, 5)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11:   val_X created with shape: (1, 6, 2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:  val_X created with shape: (1, 6, 2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11:   val_Y created with shape: (1, 5, 5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:  val_Y created with shape: (1, 5, 5)\n"
          ]
        }
      ],
      "source": [
        "##============================================================##\n",
        "##  Shuffle and split data into training and validation sets  ##\n",
        "##============================================================##\n",
        "\n",
        "##  Enumerate datapoints and shuffle\n",
        "idcs = np.arange(len(X))\n",
        "np.random.shuffle(idcs)\n",
        "\n",
        "##  Separate indices into train and validation sets\n",
        "val_split            = config[\"training\"][\"validation_split\"]\n",
        "split_idx            = int(val_split*len(idcs))\n",
        "train_idcs, val_idcs = idcs[split_idx:], idcs[:split_idx]\n",
        "logger.info(f\"Validation split is {val_split}\")\n",
        "logger.info(f\"Assigned following indicies for training data: {train_idcs}\")\n",
        "logger.info(f\"Assigned following indicies for validation data: {val_idcs}\")\n",
        "\n",
        "##  Create train and validation sets\n",
        "train_X, train_Y = X[train_idcs], Y[train_idcs]\n",
        "val_X  , val_Y   = X[  val_idcs], Y[  val_idcs]\n",
        "logger.info(f\"train_X created with shape: {train_X.shape}\")\n",
        "logger.info(f\"train_Y created with shape: {train_Y.shape}\")\n",
        "logger.info(f\"  val_X created with shape: {  val_X.shape}\")\n",
        "logger.info(f\"  val_Y created with shape: {  val_Y.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyJGjvHGw5eT",
        "outputId": "704b7633-12a5-4555-a526-d5ed95fb1a00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11: Training for maximum of 500 epochs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Training for maximum of 500 epochs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:09:11: Early stopping with minitor 'loss' and patience=10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Early stopping with minitor 'loss' and patience=10\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 13s 13s/step - loss: 1.1459 - accuracy: 0.2000\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.4519 - accuracy: 0.4000\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 251ms/step - loss: 0.2429 - accuracy: 0.2000\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.1820 - accuracy: 0.0000e+00\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.1629 - accuracy: 0.2000\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.1606 - accuracy: 0.0000e+00\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.1589 - accuracy: 0.0000e+00\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.1579 - accuracy: 0.0000e+00\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.1570 - accuracy: 0.0000e+00\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.1562 - accuracy: 0.0000e+00\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.1552 - accuracy: 0.0000e+00\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.1537 - accuracy: 0.0000e+00\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.1518 - accuracy: 0.2000\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.1494 - accuracy: 0.2000\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.1474 - accuracy: 0.2000\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.1457 - accuracy: 0.2000\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.1439 - accuracy: 0.2000\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.1420 - accuracy: 0.2000\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.1405 - accuracy: 0.2000\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.1389 - accuracy: 0.2000\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.1370 - accuracy: 0.2000\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.1347 - accuracy: 0.2000\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.1325 - accuracy: 0.2000\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.1302 - accuracy: 0.2000\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 244ms/step - loss: 0.1278 - accuracy: 0.2000\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 315ms/step - loss: 0.1252 - accuracy: 0.2000\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 0.1231 - accuracy: 0.2000\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 368ms/step - loss: 0.1213 - accuracy: 0.2000\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.1195 - accuracy: 0.2000\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 0.1174 - accuracy: 0.2000\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.1154 - accuracy: 0.2000\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 0.1135 - accuracy: 0.2000\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.1114 - accuracy: 0.2000\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 0.1094 - accuracy: 0.2000\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.1077 - accuracy: 0.2000\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 366ms/step - loss: 0.1061 - accuracy: 0.2000\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 304ms/step - loss: 0.1042 - accuracy: 0.2000\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.1024 - accuracy: 0.2000\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 284ms/step - loss: 0.1005 - accuracy: 0.2000\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.0984 - accuracy: 0.2000\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.0960 - accuracy: 0.2000\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0938 - accuracy: 0.2000\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.0919 - accuracy: 0.2000\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.0900 - accuracy: 0.2000\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.0880 - accuracy: 0.2000\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.0860 - accuracy: 0.2000\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.0839 - accuracy: 0.2000\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.0815 - accuracy: 0.2000\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.0794 - accuracy: 0.2000\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.0774 - accuracy: 0.2000\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 248ms/step - loss: 0.0750 - accuracy: 0.2000\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.0728 - accuracy: 0.2000\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.0709 - accuracy: 0.2000\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.0689 - accuracy: 0.2000\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.0669 - accuracy: 0.2000\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.0649 - accuracy: 0.2000\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.0629 - accuracy: 0.2000\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.0608 - accuracy: 0.2000\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0586 - accuracy: 0.2000\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0564 - accuracy: 0.2000\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.0544 - accuracy: 0.2000\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.0522 - accuracy: 0.2000\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.0502 - accuracy: 0.2000\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.0481 - accuracy: 0.2000\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.0461 - accuracy: 0.2000\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.0441 - accuracy: 0.2000\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.0419 - accuracy: 0.2000\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.0400 - accuracy: 0.2000\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0382 - accuracy: 0.2000\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.0365 - accuracy: 0.2000\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.0349 - accuracy: 0.2000\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.0335 - accuracy: 0.2000\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.0318 - accuracy: 0.2000\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.0302 - accuracy: 0.2000\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.0288 - accuracy: 0.2000\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0274 - accuracy: 0.2000\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.0262 - accuracy: 0.2000\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.0248 - accuracy: 0.2000\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0234 - accuracy: 0.2000\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 0.0223 - accuracy: 0.2000\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.0212 - accuracy: 0.2000\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 0.0202 - accuracy: 0.2000\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 372ms/step - loss: 0.0192 - accuracy: 0.2000\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 0.0183 - accuracy: 0.2000\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 0.0175 - accuracy: 0.2000\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 0.0167 - accuracy: 0.2000\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.0159 - accuracy: 0.2000\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 0.0152 - accuracy: 0.2000\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 0.0145 - accuracy: 0.2000\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 0.0138 - accuracy: 0.2000\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.0132 - accuracy: 0.2000\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0127 - accuracy: 0.2000\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.0122 - accuracy: 0.2000\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.0118 - accuracy: 0.2000\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 0.0113 - accuracy: 0.2000\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.0109 - accuracy: 0.2000\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.0104 - accuracy: 0.2000\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.0101 - accuracy: 0.2000\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.0097 - accuracy: 0.2000\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.0093 - accuracy: 0.2000\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.0091 - accuracy: 0.2000\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.0087 - accuracy: 0.2000\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.0084 - accuracy: 0.2000\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 0.0081 - accuracy: 0.2000\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 0.0079 - accuracy: 0.2000\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.0077 - accuracy: 0.2000\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0074 - accuracy: 0.2000\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.0072 - accuracy: 0.2000\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 238ms/step - loss: 0.0070 - accuracy: 0.2000\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.0067 - accuracy: 0.2000\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0066 - accuracy: 0.2000\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.0064 - accuracy: 0.2000\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.0062 - accuracy: 0.2000\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.0060 - accuracy: 0.2000\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.0059 - accuracy: 0.2000\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.0057 - accuracy: 0.2000\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.0055 - accuracy: 0.2000\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.0054 - accuracy: 0.2000\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.0053 - accuracy: 0.2000\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.0052 - accuracy: 0.2000\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.0050 - accuracy: 0.2000\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.0049 - accuracy: 0.2000\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.0048 - accuracy: 0.2000\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.0047 - accuracy: 0.2000\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.0046 - accuracy: 0.2000\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.0045 - accuracy: 0.2000\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.0044 - accuracy: 0.2000\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.0043 - accuracy: 0.2000\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.0042 - accuracy: 0.2000\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.0041 - accuracy: 0.2000\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 0.0040 - accuracy: 0.2000\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.0039 - accuracy: 0.2000\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.0038 - accuracy: 0.2000\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.0037 - accuracy: 0.2000\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 0.0037 - accuracy: 0.2000\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 0.0036 - accuracy: 0.2000\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 375ms/step - loss: 0.0035 - accuracy: 0.2000\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 0.0035 - accuracy: 0.2000\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 0.0034 - accuracy: 0.2000\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 0.0033 - accuracy: 0.2000\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 0.0033 - accuracy: 0.2000\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 0.0032 - accuracy: 0.2000\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 0.0031 - accuracy: 0.2000\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 348ms/step - loss: 0.0031 - accuracy: 0.2000\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 0.0030 - accuracy: 0.2000\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 0.0030 - accuracy: 0.2000\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 0.0029 - accuracy: 0.2000\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.0029 - accuracy: 0.2000\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.0028 - accuracy: 0.2000\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.0028 - accuracy: 0.2000\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 0.0027 - accuracy: 0.2000\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.0027 - accuracy: 0.2000\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 0.0026 - accuracy: 0.2000\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0026 - accuracy: 0.2000\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.0026 - accuracy: 0.2000\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.0025 - accuracy: 0.2000\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.0025 - accuracy: 0.2000\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.0024 - accuracy: 0.2000\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.0024 - accuracy: 0.2000\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0024 - accuracy: 0.2000\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.0023 - accuracy: 0.2000\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.0023 - accuracy: 0.2000\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.0023 - accuracy: 0.2000\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.0022 - accuracy: 0.2000\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.0022 - accuracy: 0.2000\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.0022 - accuracy: 0.2000\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.0021 - accuracy: 0.2000\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 0.0021 - accuracy: 0.2000\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.0021 - accuracy: 0.2000\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0021 - accuracy: 0.2000\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 0.0020 - accuracy: 0.2000\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.0020 - accuracy: 0.2000\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.0020 - accuracy: 0.2000\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.0020 - accuracy: 0.2000\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.0019 - accuracy: 0.2000\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.0019 - accuracy: 0.2000\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.0019 - accuracy: 0.2000\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 0.0019 - accuracy: 0.2000\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.0018 - accuracy: 0.2000\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.0018 - accuracy: 0.2000\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.0018 - accuracy: 0.2000\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 0.0018 - accuracy: 0.2000\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.0017 - accuracy: 0.2000\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.0017 - accuracy: 0.2000\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.0017 - accuracy: 0.2000\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 0.0017 - accuracy: 0.2000\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.0016 - accuracy: 0.2000\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.0016 - accuracy: 0.2000\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0016 - accuracy: 0.2000\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 333ms/step - loss: 0.0016 - accuracy: 0.2000\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 0.0016 - accuracy: 0.2000\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 0.0015 - accuracy: 0.2000\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 392ms/step - loss: 0.0015 - accuracy: 0.2000\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 0.0015 - accuracy: 0.2000\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 359ms/step - loss: 0.0015 - accuracy: 0.2000\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 0.0015 - accuracy: 0.2000\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 374ms/step - loss: 0.0015 - accuracy: 0.2000\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 0.0014 - accuracy: 0.2000\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 0.0014 - accuracy: 0.2000\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 344ms/step - loss: 0.0014 - accuracy: 0.2000\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 0.0014 - accuracy: 0.2000\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 0.0014 - accuracy: 0.2000\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.0014 - accuracy: 0.2000\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 0.0013 - accuracy: 0.2000\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.0013 - accuracy: 0.2000\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.0013 - accuracy: 0.2000\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 0.0013 - accuracy: 0.2000\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0013 - accuracy: 0.2000\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.0013 - accuracy: 0.2000\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.0013 - accuracy: 0.2000\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.0012 - accuracy: 0.2000\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0012 - accuracy: 0.2000\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.0012 - accuracy: 0.2000\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.0012 - accuracy: 0.2000\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.0012 - accuracy: 0.2000\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0012 - accuracy: 0.2000\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.0012 - accuracy: 0.2000\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 0.0011 - accuracy: 0.2000\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 0.0011 - accuracy: 0.2000\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.0011 - accuracy: 0.2000\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.0011 - accuracy: 0.2000\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.0011 - accuracy: 0.2000\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.0011 - accuracy: 0.2000\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 0.0011 - accuracy: 0.2000\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0011 - accuracy: 0.2000\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 0.0010 - accuracy: 0.2000\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 0.0010 - accuracy: 0.2000\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.0010 - accuracy: 0.2000\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 0.0010 - accuracy: 0.2000\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 9.9994e-04 - accuracy: 0.2000\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 9.8865e-04 - accuracy: 0.2000\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 9.7786e-04 - accuracy: 0.2000\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 9.6705e-04 - accuracy: 0.2000\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 9.5570e-04 - accuracy: 0.2000\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 9.4567e-04 - accuracy: 0.2000\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 9.3565e-04 - accuracy: 0.2000\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 9.2571e-04 - accuracy: 0.2000\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 9.1569e-04 - accuracy: 0.2000\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 9.0701e-04 - accuracy: 0.2000\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 8.9745e-04 - accuracy: 0.2000\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 8.8841e-04 - accuracy: 0.2000\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 8.7972e-04 - accuracy: 0.2000\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 8.7065e-04 - accuracy: 0.2000\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 8.6221e-04 - accuracy: 0.2000\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 8.5288e-04 - accuracy: 0.2000\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 8.4449e-04 - accuracy: 0.2000\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 8.3630e-04 - accuracy: 0.2000\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 355ms/step - loss: 8.2809e-04 - accuracy: 0.2000\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 8.2021e-04 - accuracy: 0.2000\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 8.1247e-04 - accuracy: 0.2000\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 8.0463e-04 - accuracy: 0.2000\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 7.9702e-04 - accuracy: 0.2000\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 7.8951e-04 - accuracy: 0.2000\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 354ms/step - loss: 7.8186e-04 - accuracy: 0.2000\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 7.7436e-04 - accuracy: 0.2000\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 335ms/step - loss: 7.6706e-04 - accuracy: 0.2000\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 7.6010e-04 - accuracy: 0.2000\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 7.5312e-04 - accuracy: 0.2000\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 7.4620e-04 - accuracy: 0.2000\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 7.3934e-04 - accuracy: 0.2000\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 7.3277e-04 - accuracy: 0.2000\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 7.2604e-04 - accuracy: 0.2000\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 7.1949e-04 - accuracy: 0.2000\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 7.1322e-04 - accuracy: 0.2000\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 7.0658e-04 - accuracy: 0.2000\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 6.9994e-04 - accuracy: 0.2000\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 6.9352e-04 - accuracy: 0.2000\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 6.8761e-04 - accuracy: 0.2000\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 6.8144e-04 - accuracy: 0.2000\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 6.7495e-04 - accuracy: 0.2000\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 6.6889e-04 - accuracy: 0.2000\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 6.6259e-04 - accuracy: 0.2000\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 6.5654e-04 - accuracy: 0.2000\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 6.5055e-04 - accuracy: 0.2000\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 6.4500e-04 - accuracy: 0.2000\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 6.3897e-04 - accuracy: 0.2000\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 6.3340e-04 - accuracy: 0.2000\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 6.2763e-04 - accuracy: 0.2000\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 6.2209e-04 - accuracy: 0.2000\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 6.1661e-04 - accuracy: 0.2000\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 6.1125e-04 - accuracy: 0.2000\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 6.0560e-04 - accuracy: 0.2000\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 6.0041e-04 - accuracy: 0.2000\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 5.9515e-04 - accuracy: 0.2000\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 5.9007e-04 - accuracy: 0.2000\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 5.8483e-04 - accuracy: 0.2000\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 5.8017e-04 - accuracy: 0.2000\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 5.7518e-04 - accuracy: 0.2000\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 5.7050e-04 - accuracy: 0.2000\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 5.6559e-04 - accuracy: 0.2000\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 5.6054e-04 - accuracy: 0.2000\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 5.5614e-04 - accuracy: 0.2000\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 5.5118e-04 - accuracy: 0.2000\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 5.4706e-04 - accuracy: 0.2000\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 5.4261e-04 - accuracy: 0.2000\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 5.3805e-04 - accuracy: 0.2000\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 5.3333e-04 - accuracy: 0.2000\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 5.2923e-04 - accuracy: 0.2000\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 5.2463e-04 - accuracy: 0.2000\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 5.2042e-04 - accuracy: 0.2000\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 369ms/step - loss: 5.1623e-04 - accuracy: 0.2000\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 5.1187e-04 - accuracy: 0.2000\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 5.0813e-04 - accuracy: 0.2000\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 347ms/step - loss: 5.0349e-04 - accuracy: 0.2000\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 4.9946e-04 - accuracy: 0.2000\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 4.9576e-04 - accuracy: 0.2000\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 4.9157e-04 - accuracy: 0.2000\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 4.8804e-04 - accuracy: 0.2000\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 4.8429e-04 - accuracy: 0.2000\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 4.8042e-04 - accuracy: 0.2000\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 339ms/step - loss: 4.7673e-04 - accuracy: 0.2000\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 353ms/step - loss: 4.7316e-04 - accuracy: 0.2000\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 4.6960e-04 - accuracy: 0.2000\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 4.6591e-04 - accuracy: 0.2000\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 4.6235e-04 - accuracy: 0.2000\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 4.5892e-04 - accuracy: 0.2000\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 4.5572e-04 - accuracy: 0.2000\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 4.5222e-04 - accuracy: 0.2000\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 4.4891e-04 - accuracy: 0.2000\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 4.4562e-04 - accuracy: 0.2000\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 4.4231e-04 - accuracy: 0.2000\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 4.3921e-04 - accuracy: 0.2000\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 4.3628e-04 - accuracy: 0.2000\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 4.3319e-04 - accuracy: 0.2000\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 4.3002e-04 - accuracy: 0.2000\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 4.2707e-04 - accuracy: 0.2000\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 4.2424e-04 - accuracy: 0.2000\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 4.2116e-04 - accuracy: 0.2000\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 4.1834e-04 - accuracy: 0.2000\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 4.1531e-04 - accuracy: 0.2000\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 4.1243e-04 - accuracy: 0.2000\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 4.0962e-04 - accuracy: 0.2000\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 4.0675e-04 - accuracy: 0.2000\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 4.0411e-04 - accuracy: 0.2000\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 4.0115e-04 - accuracy: 0.2000\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 3.9839e-04 - accuracy: 0.2000\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 3.9576e-04 - accuracy: 0.2000\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 1s 515ms/step - loss: 3.9312e-04 - accuracy: 0.2000\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 3.9041e-04 - accuracy: 0.2000\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 3.8778e-04 - accuracy: 0.2000\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 3.8513e-04 - accuracy: 0.2000\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 3.8259e-04 - accuracy: 0.2000\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 3.8002e-04 - accuracy: 0.2000\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 3.7732e-04 - accuracy: 0.2000\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 3.7496e-04 - accuracy: 0.2000\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 3.7222e-04 - accuracy: 0.2000\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 3.7007e-04 - accuracy: 0.2000\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 3.6743e-04 - accuracy: 0.2000\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 3.6508e-04 - accuracy: 0.2000\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 3.6260e-04 - accuracy: 0.2000\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 3.6000e-04 - accuracy: 0.2000\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 3.5787e-04 - accuracy: 0.2000\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 3.5517e-04 - accuracy: 0.2000\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 297ms/step - loss: 3.5299e-04 - accuracy: 0.2000\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 3.5057e-04 - accuracy: 0.2000\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 3.4825e-04 - accuracy: 0.2000\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 367ms/step - loss: 3.4598e-04 - accuracy: 0.2000\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 3.4370e-04 - accuracy: 0.2000\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 357ms/step - loss: 3.4140e-04 - accuracy: 0.2000\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 355ms/step - loss: 3.3909e-04 - accuracy: 0.2000\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 3.3702e-04 - accuracy: 0.2000\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 363ms/step - loss: 3.3471e-04 - accuracy: 0.2000\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 329ms/step - loss: 3.3247e-04 - accuracy: 0.2000\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 336ms/step - loss: 3.3021e-04 - accuracy: 0.2000\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 364ms/step - loss: 3.2806e-04 - accuracy: 0.2000\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 3.2602e-04 - accuracy: 0.2000\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 3.2395e-04 - accuracy: 0.2000\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 3.2182e-04 - accuracy: 0.2000\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 3.1986e-04 - accuracy: 0.2000\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 3.1767e-04 - accuracy: 0.2000\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 3.1580e-04 - accuracy: 0.2000\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 3.1360e-04 - accuracy: 0.2000\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 3.1182e-04 - accuracy: 0.2000\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 3.0971e-04 - accuracy: 0.2000\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 3.0769e-04 - accuracy: 0.2000\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 3.0592e-04 - accuracy: 0.2000\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 3.0382e-04 - accuracy: 0.2000\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 3.0212e-04 - accuracy: 0.2000\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 3.0020e-04 - accuracy: 0.2000\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 223ms/step - loss: 2.9824e-04 - accuracy: 0.2000\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 2.9652e-04 - accuracy: 0.2000\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 2.9470e-04 - accuracy: 0.2000\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 2.9300e-04 - accuracy: 0.2000\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 2.9116e-04 - accuracy: 0.2000\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 2.8962e-04 - accuracy: 0.2000\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 2.8793e-04 - accuracy: 0.2000\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 2.8614e-04 - accuracy: 0.2000\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 2.8447e-04 - accuracy: 0.2000\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 2.8278e-04 - accuracy: 0.2000\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 2.8086e-04 - accuracy: 0.2000\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 2.7915e-04 - accuracy: 0.2000\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 2.7741e-04 - accuracy: 0.2000\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 2.7569e-04 - accuracy: 0.2000\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 2.7400e-04 - accuracy: 0.2000\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 2.7242e-04 - accuracy: 0.2000\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 2.7058e-04 - accuracy: 0.2000\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 2.6908e-04 - accuracy: 0.2000\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 2.6722e-04 - accuracy: 0.2000\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 2.6565e-04 - accuracy: 0.2000\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 2.6397e-04 - accuracy: 0.2000\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 2.6237e-04 - accuracy: 0.2000\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 2.6081e-04 - accuracy: 0.2000\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 2.5915e-04 - accuracy: 0.2000\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 242ms/step - loss: 2.5754e-04 - accuracy: 0.2000\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 2.5599e-04 - accuracy: 0.2000\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 2.5443e-04 - accuracy: 0.2000\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 2.5288e-04 - accuracy: 0.2000\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 338ms/step - loss: 2.5131e-04 - accuracy: 0.2000\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 2.4999e-04 - accuracy: 0.2000\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 2.4850e-04 - accuracy: 0.2000\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 378ms/step - loss: 2.4705e-04 - accuracy: 0.2000\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 330ms/step - loss: 2.4565e-04 - accuracy: 0.2000\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 2.4424e-04 - accuracy: 0.2000\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 377ms/step - loss: 2.4284e-04 - accuracy: 0.2000\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 376ms/step - loss: 2.4149e-04 - accuracy: 0.2000\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 345ms/step - loss: 2.4016e-04 - accuracy: 0.2000\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 2.3880e-04 - accuracy: 0.2000\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 341ms/step - loss: 2.3743e-04 - accuracy: 0.2000\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 346ms/step - loss: 2.3616e-04 - accuracy: 0.2000\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 342ms/step - loss: 2.3477e-04 - accuracy: 0.2000\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 2.3350e-04 - accuracy: 0.2000\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 2.3220e-04 - accuracy: 0.2000\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 2.3093e-04 - accuracy: 0.2000\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 2.2960e-04 - accuracy: 0.2000\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 2.2840e-04 - accuracy: 0.2000\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 2.2716e-04 - accuracy: 0.2000\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 2.2587e-04 - accuracy: 0.2000\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 2.2461e-04 - accuracy: 0.2000\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 2.2338e-04 - accuracy: 0.2000\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 2.2219e-04 - accuracy: 0.2000\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 2.2108e-04 - accuracy: 0.2000\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 2.1981e-04 - accuracy: 0.2000\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 2.1879e-04 - accuracy: 0.2000\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 2.1749e-04 - accuracy: 0.2000\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 2.1646e-04 - accuracy: 0.2000\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 2.1528e-04 - accuracy: 0.2000\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 2.1407e-04 - accuracy: 0.2000\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 2.1318e-04 - accuracy: 0.2000\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 2.1180e-04 - accuracy: 0.2000\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 2.1078e-04 - accuracy: 0.2000\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 2.0966e-04 - accuracy: 0.2000\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 2.0849e-04 - accuracy: 0.2000\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 2.0749e-04 - accuracy: 0.2000\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 2.0639e-04 - accuracy: 0.2000\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 2.0533e-04 - accuracy: 0.2000\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 2.0430e-04 - accuracy: 0.2000\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 237ms/step - loss: 2.0324e-04 - accuracy: 0.2000\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 2.0223e-04 - accuracy: 0.2000\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 2.0123e-04 - accuracy: 0.2000\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 2.0023e-04 - accuracy: 0.2000\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 235ms/step - loss: 1.9920e-04 - accuracy: 0.2000\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 1.9821e-04 - accuracy: 0.2000\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 1.9721e-04 - accuracy: 0.2000\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 1.9621e-04 - accuracy: 0.2000\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 220ms/step - loss: 1.9527e-04 - accuracy: 0.2000\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 1.9427e-04 - accuracy: 0.2000\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 1.9335e-04 - accuracy: 0.2000\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 1.9237e-04 - accuracy: 0.2000\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 1.9144e-04 - accuracy: 0.2000\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 1.9048e-04 - accuracy: 0.2000\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 1.8954e-04 - accuracy: 0.2000\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 1.8864e-04 - accuracy: 0.2000\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.8771e-04 - accuracy: 0.2000\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 349ms/step - loss: 1.8682e-04 - accuracy: 0.2000\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 358ms/step - loss: 1.8586e-04 - accuracy: 0.2000\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 362ms/step - loss: 1.8496e-04 - accuracy: 0.2000\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 1.8410e-04 - accuracy: 0.2000\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 340ms/step - loss: 1.8317e-04 - accuracy: 0.2000\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 351ms/step - loss: 1.8231e-04 - accuracy: 0.2000\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.8146e-04 - accuracy: 0.2000\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 361ms/step - loss: 1.8056e-04 - accuracy: 0.2000\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 1.7971e-04 - accuracy: 0.2000\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 360ms/step - loss: 1.7883e-04 - accuracy: 0.2000\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 356ms/step - loss: 1.7805e-04 - accuracy: 0.2000\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 322ms/step - loss: 1.7721e-04 - accuracy: 0.2000\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 1.7639e-04 - accuracy: 0.2000\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 1.7556e-04 - accuracy: 0.2000\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 1.7475e-04 - accuracy: 0.2000\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 1.7395e-04 - accuracy: 0.2000\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 1.7315e-04 - accuracy: 0.2000\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 1.7238e-04 - accuracy: 0.2000\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 1.7157e-04 - accuracy: 0.2000\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 247ms/step - loss: 1.7074e-04 - accuracy: 0.2000\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 1.6997e-04 - accuracy: 0.2000\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 224ms/step - loss: 1.6921e-04 - accuracy: 0.2000\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 226ms/step - loss: 1.6845e-04 - accuracy: 0.2000\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 241ms/step - loss: 1.6774e-04 - accuracy: 0.2000\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 218ms/step - loss: 1.6695e-04 - accuracy: 0.2000\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 1.6626e-04 - accuracy: 0.2000\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 1.6551e-04 - accuracy: 0.2000\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 1.6473e-04 - accuracy: 0.2000\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 1.6406e-04 - accuracy: 0.2000\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 227ms/step - loss: 1.6329e-04 - accuracy: 0.2000\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 1.6261e-04 - accuracy: 0.2000\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 1.6190e-04 - accuracy: 0.2000\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 243ms/step - loss: 1.6118e-04 - accuracy: 0.2000\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 1.6048e-04 - accuracy: 0.2000\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 1.5980e-04 - accuracy: 0.2000\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 1.5912e-04 - accuracy: 0.2000\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 1.5845e-04 - accuracy: 0.2000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d08acd0a530>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "##=============##\n",
        "##  Fit model  ##\n",
        "##=============##\n",
        "\n",
        "##  Resolve training config\n",
        "epochs     = config[\"training\"].get(\"epochs\", 100)\n",
        "batch_size = config[\"training\"].get(\"batch_size\", 32)\n",
        "monitor    = config[\"training\"].get(\"early_stopping\", {}).get(\"monitor\" , \"loss\")\n",
        "patience   = config[\"training\"].get(\"early_stopping\", {}).get(\"patience\", 10    )\n",
        "\n",
        "##  Log settings\n",
        "logger.info(f\"Training for maximum of {epochs} epochs\")\n",
        "logger.info(f\"Early stopping with minitor '{monitor}' and patience={patience}\")\n",
        "\n",
        "##  Fit model\n",
        "model.fit(train_X,\n",
        "          train_Y,\n",
        "          epochs     = epochs,\n",
        "          batch_size = batch_size,\n",
        "          callbacks  = [tf.keras.callbacks.EarlyStopping(monitor=monitor, patience=patience, restore_best_weights=True)],\n",
        "         )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHYblzC90jev",
        "outputId": "3df06492-8757-42c9-b649-7e98ee229e5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:11:50: Training set: loss = 0.0001578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Training set: loss = 0.0001578\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:11:50: Training set: accuracy = 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Training set: accuracy = 0.2\n"
          ]
        }
      ],
      "source": [
        "##================================##\n",
        "##  Evaluate model on train data  ##\n",
        "##================================##\n",
        "\n",
        "evals = model.evaluate(train_X, train_Y, verbose=0)\n",
        "for metric_name, metric_value in zip(model.metrics_names, evals) :\n",
        "        logger.info(f\"Training set: {metric_name} = {metric_value:.4}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORFpesCf0xvW",
        "outputId": "eadce70b-765c-466f-c607-0cfda7e11e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:11:50: Validation set: loss = 0.0001578\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Validation set: loss = 0.0001578\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:11:50: Validation set: accuracy = 0.2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Validation set: accuracy = 0.2\n"
          ]
        }
      ],
      "source": [
        "##=====================================##\n",
        "##  Evaluate model on validation data  ##\n",
        "##=====================================##\n",
        "\n",
        "evals = model.evaluate(val_X, val_Y, verbose=0)\n",
        "for metric_name, metric_value in zip(model.metrics_names, evals) :\n",
        "        logger.info(f\"Validation set: {metric_name} = {metric_value:.4}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K34jTIvd0zjH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4idGN9lR04bX"
      },
      "outputs": [],
      "source": [
        "##======================================================================##\n",
        "##  Define quick method for plotting a true map against its prediction  ##\n",
        "##======================================================================##\n",
        "\n",
        "def plot_maps(Y_true : np.ndarray,\n",
        "              Y_pred : np.ndarray,\n",
        "              X_true : np.ndarray | None = None,\n",
        "              show   : bool              = True,\n",
        "              close  : bool              = True,\n",
        "             ) -> plt.Figure :\n",
        "    \"\"\"\n",
        "    Plot a true pixel-map side-by-side with that predicted by a model\n",
        "    Optionally also plot the true trajectory\n",
        "    Returns the figure object\n",
        "    \"\"\"\n",
        "    ##  Create figure\n",
        "    fig = plt.figure(figsize=(6.3, 3))\n",
        "    fig.subplots_adjust(wspace=.3/3)\n",
        "\n",
        "    ##  Create and format axes\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    ax2 = fig.add_subplot(1, 2, 2)\n",
        "    ax1.tick_params(left=False, bottom=False, top=False, right=False)\n",
        "    ax2.tick_params(left=False, bottom=False, top=False, right=False)\n",
        "    ax1.xaxis.set_ticklabels([])\n",
        "    ax2.xaxis.set_ticklabels([])\n",
        "    ax1.yaxis.set_ticklabels([])\n",
        "    ax2.yaxis.set_ticklabels([])\n",
        "    ax1.set_title(\"True\", weight=\"bold\", fontsize=14)\n",
        "    ax2.set_title(\"Pred\", weight=\"bold\", fontsize=14)\n",
        "\n",
        "    #\n",
        "\n",
        "    ##  Plot pixel maps\n",
        "    print(\"Y_true\",Y_true)\n",
        "    ax1.imshow(Y_true.T, origin=\"lower\", cmap=\"Greys\")\n",
        "    ax2.imshow(Y_pred.T, origin=\"lower\", cmap=\"Greys\")\n",
        "\n",
        "    #plt.show(fig)\n",
        "\n",
        "    ##  Plot trajectory\n",
        "    ##  N.B. we must subtract 1 from pixel locations to account for earlier offset\n",
        "    if X_true is not None :\n",
        "        x_last, y_last = None, None\n",
        "        for x, y in X_true[1:-1] - 1 :\n",
        "            ax1.plot(x, y, \"o\", ms=10, c=\"blue\")\n",
        "            ax2.plot(x, y, \"o\", ms=10, c=\"orange\")\n",
        "            if x_last is not None :\n",
        "                ax1.plot([x_last, x], [y_last, y], \"--\", lw=2, c=\"r\")\n",
        "                ax2.plot([x_last, x], [y_last, y], \"--\", lw=2, c=\"g\")\n",
        "            x_last, y_last = x, y\n",
        "\n",
        "    ##  Show figure\n",
        "    if show :\n",
        "        plt.show(fig)\n",
        "\n",
        "    ##  Close figure\n",
        "    if close :\n",
        "        plt.close(fig)\n",
        "\n",
        "    ##  Return figure\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2j49zPAP07lO",
        "outputId": "95ba58b8-acb8-412b-d078-9184ff07f254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_X [[[6 6]\n",
            "  [1 1]\n",
            "  [2 2]\n",
            "  [1 3]\n",
            "  [1 4]\n",
            "  [7 7]]\n",
            "\n",
            " [[6 6]\n",
            "  [1 1]\n",
            "  [2 2]\n",
            "  [1 3]\n",
            "  [1 4]\n",
            "  [7 7]]\n",
            "\n",
            " [[6 6]\n",
            "  [1 1]\n",
            "  [2 2]\n",
            "  [1 3]\n",
            "  [1 4]\n",
            "  [7 7]]\n",
            "\n",
            " [[6 6]\n",
            "  [1 1]\n",
            "  [2 2]\n",
            "  [1 3]\n",
            "  [1 4]\n",
            "  [7 7]]\n",
            "\n",
            " [[6 6]\n",
            "  [1 1]\n",
            "  [2 2]\n",
            "  [1 3]\n",
            "  [1 4]\n",
            "  [7 7]]]\n",
            "   INFO 2023-11-28 10:26:23: Training set row 0 with\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Training set row 0 with\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Y_true [[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 630x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:26:23: Training set row 1 with\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Training set row 1 with\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Y_true [[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAESCAYAAAAVAhemAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAe/klEQVR4nO3df3RU9Z3/8dfN7wn5RQIiIRwlMYp23Z6IFaH2q2ghFfyBjYhr1bS0Z9ethfOF1a/ucWvd+rWmFll+tF231a8NLVaXEl0x0aiAihY5R7GuuweQErJHEqCGkF8mMITc7x+fSciPSTJJZu7N3Hk+zpkzmftj5pM/Pu/X3Hs/9zOWbdu2AACAJ8W53QAAABA5BD0AAB5G0AMA4GEEPQAAHkbQAwDgYQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQBgTCzL6nn85je/cbs56IegH6fOP//8Pp0nlMdbb73ldrMBhMFbb701aD9PS0vTJZdcouXLl6umpsbtpiIKEPQAEEW++OIL7d27Vz//+c916aWX6s0333S7SRjnEtxuAIJ76KGH1Nzc3PP6xIkT+slPftLzev78+VqwYEGffQoKCoK+V0tLizIyMiLTUAARt3TpUl1++eXy+/3atWuXXnnlFUlSe3u77rrrLtXW1io5OXnI96AOxDAbUeHQoUO2pJ7Hj370o0HX7dixw3766aftoqIiOyUlxf7yl79s27Ztl5aW9mxz9dVX93n/HTt29HmPQ4cO9Vl/5swZe+PGjfb8+fPtyZMn24mJifakSZPshQsX2pWVlZH954EY078/Pvvss33Wf+tb3+qzftu2bQP2OXDggP2zn/3Mnjlzpp2UlGTffPPNPfuPpj+fPn3afvzxx+0LLrjATkpKsvPz8+1HH33U9vv9Q7YV7uOI3oMefvhh7dy5M2zv19HRoZtuumnAKcKGhgZVVVWpqqpKq1at0pNPPhm2zwQwuDlz5mjTpk09r48eParc3Nw+2yxbtixoHRhtf77rrrv0/PPP97yuqanRD3/4Q73//vvh+JcQQQS9B+3cuVPnnXeeSkpKlJqaqr/85S9jer+VK1f2FIWkpCTdfvvtKiws1CeffKLNmzfLtm2tWbNGs2bN0h133BGOfwHAEHbt2tXn9bnnnjtgm507d+pLX/qSbrzxRtm2rfj4eEmj689/+MMf+oT8BRdcoNtuu011dXX67W9/G6l/E2FC0HvQjBkztGfPHmVlZY35vRobG/XMM8/0vH7qqaf0ne98p+f1pEmT9Mtf/lKStHr1aoIeiIDXXntNDQ0N8vv9ev/997V169aedVOmTNHcuXMHHFlfeeWV2rFjh1JSUnqWjbY/P/300z3bZGZmavfu3crOzpYkXXjhhXrooYfC+N8i3Ah6D7r33nvDEvKStHv3bnV2dva8XrZsmZYtWxZ02z/96U9qb29XampqWD4bgPHCCy/ohRdeGLA8JSVF5eXlfcK823333Tdg+Wj78wcffNCz/Bvf+EZPyEvSnXfeSdCPc9xe50EzZ84cdhvbtvu8PnXqVNDtGhsbQ/5c27Z1/PjxkLcHMHI+n08zZ87U97//fX3yyScqLi4Oul2wOjDa/tzU1NSz/Jxzzumz3ZQpU0J+T7iDI3oPmjBhQtDlcXFnv9d1dHT0WXfgwIGg+/T+5i6Z63v9B/30lpmZGWozAYTo2Wef1be//e0R7ROsDoy2P2dlZfWEfv8xP8eOHRtRu+A8gj6G9D6dv3//fjU1NSkrK0vNzc36xS9+EXSf2bNnKz4+XmfOnJEkJSYm6r777huwXW1trfbv3899usA4Ntr+fPnll6u6ulqSGS/Q2NjY86Xhd7/7nUOtx2gR9DHkK1/5Ss/fLS0tKioq0hVXXKH33ntPdXV1QffJzs7WsmXL9Otf/1qS9MQTT+iDDz7Q3LlzlZKSorq6Or3//vv66KOPVFpaOuhpRADuG21//u53v9sT9M3NzZo9e7aWLl2qw4cPM+o+ChD0MeSWW25RYWFhz2n62tpa1dbWSpIWLlyoqqqqoPutXbtWhw4d6rklZ/v27dq+fbsjbQYQXqPpz0uWLNGSJUu0efNmSdKf//xnPfbYY5Kka665ht/ZGOcYjBdDUlJStG3bNt12223KyspSSkqKZs+erRdffFH333//oPulpqaqurpazz33nBYuXKgpU6YoISFBPp9PBQUFuvXWW/WrX/1Ka9ascfC/ATAao+3PmzZt0mOPPab8/HwlJibq/PPP10MPPaRXX33Vpf8EobLs/sOvAQCAZ3BEDwCAhxH0AAB4GEEPAICHEfQAAHgYQQ8AgIcR9AAAeFhIE+Z0dXWpvr5e6enpsiwr0m0CECLbttXa2qrc3Nw+v2UQTvR/YHwKtf+HFPT19fWaPn162BoHILw+++wz5eXlReS96f/A+DZc/w8p6NPT03vejB8tAcaPlpYWTZ8+vaePRgL9HxifQu3/IQV99+m6jIwMOjowDkXylDr9Hxjfhuv/DMYDAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPCzBzQ+3ben4camtTUpLk3JyJMtys0UAHGPb0qnjUmeblJAmJVMAgEhw5Yi+qUlat04qLJQmT5ZmzDDPhYVmeVOTG60C4Ah/k7RvnbS1UKqYLL08wzxvLTTL/U1utxDwFMeDvrpaysuTVq6Uamr6rqupMcvz8sx2ADymvlp6KU/as1Jq61cA2mrM8pfyzHYAwsLRoK+ulhYtkjo6zFk72+67vntZR4fZjrAHPKS+Wnp7kdTZIckOPHoLLOvsMNsR9kBYOBb0TU1SSYkJ8q6uobft6jLblZRwGh/wBH+T9G6gAGiYAqBAAXi3hNP4QBg4FvTl5VJ7+/Ah362ry2y/cWNk2wXAATXlUme7hg/5bl1m+0MUAGCsHAl625Y2bBjdvuvXDzzFDyCK2Lb06SgLwH4KADBWjgT98ePSwYMj76+2bfZrbIxMuwA44NRxqe2gBl6TH45t9vNTAICxcOQ++ra2wdet1BplqEUtytC/aFXQbVpbzT32AKJQ5+AFYM0JqaVLyoiTVk0cZKPTreYeewCj4kjQp6UNvm6V1ihPdTqsaYMGfXp6hBoGIPISBi8Aa5qkuk5pWsIQQZ9IAQDGwpFT9zk5UkHByCe9siyzX3Z2ZNoFwAHJOVJagaSRznpnmf2SKADAWDhyRG9Z0vLlZjKc/u7RU/KpQx3yBd13xQpmxQSimmVJFy43k+H089RkqcOWfIP18YsoAMBYWbY9/BC5lpYWZWZmqrm5WRkZGaP6oKYmM+NdR0dot9jFxUk+n3T4sJSVNaqPBDwvHH3Tkc/wN5kZ7zo7FNotdnFSgk9afFhKyhrdZwIeF2rfdOw++qwsacsW8+U8bphPjYsz21VUEPKAJyRlSVcFCsCwZSdQAL5WQcgDYeDoFLjFxVJlpTlSt6yBZ+S6l/l8UlWVtGCBk60DEFG5xdLVleZIXZYGXrMPLEvwSddUSVMpAEA4OP4ztcXF5nT8xo1mMpzMgx8qSX75laTm/FlasUIqLZUyM51uGYCIyy02p+MPbZT2r9eHDQflt6UkS5o1Kd9ck59RKiVRAIBwcewafTC2LXVNy1P8kTqdmTpNcXWHGXcDjEDUXKMPxraV9y/TVNd6RNPSp+rwyjoG3gEjEGrfdPyIvjfLkuIDFw/i4zTyu28ARK8+1+vjCHkgQhz/PXoAAOAcgh4AAA8j6AEA8DCCHgAADyPoAQDwMIIeAAAPI+gBAPAwgh4AAA9zdcIcSdLevWaKPCbLAGLO3nv3ypYti9mygIhxP+jT091uAQCXpCfT/4FI49Q9AAAeRtADAOBh7p+6X7NGammRMjKkVavcbg0AB63ZtUYtp1qUkZyhVXPo/0AkjI+gr6uTpk0j6IEYs2bXGtW11mla+jSCHogQTt0DAOBhBD0AAB5G0AMA4GEEPQAAHkbQAwDgYQQ9AAAeRtADAOBhBD0AAB7m/oQ5l10mTZ8uTZ7sdksAOOyyqZdpeuZ0TU6l/wOR4n7Qv/yy2y0A4JKX/4b+D0Qap+4BAPAwgh4AAA8j6AEA8DD3r9HfdJP0+edmMB7X64GYctPvb9Ln7Z9rcupkrtcDEeJ+0O/Zc/ZnagHElD1H9vT8TC2AyHD11L1tS2e6zN9nusxrADHCtiU7UABsCgAQKa4EfVOTtG6dVFgoHTlilh05Yl6vW2fWA/Aof5O0b520tVA6GSgAJ4+Y1/vWmfUAwsbxoK+ulvLypJUrpZqavutqaszyvDyzHQCPqa+WXsqT9qyU2voVgLYas/ylPLMdgLBwNOirq6VFi6SOjsBZu35n6rqXdXSY7Qh7wEPqq6W3F0mdHZLswKO3wLLODrMdYQ+EhWNB39QklZSYIO/qGnrbrsDlupISTuMDnuBvkt4NFAANUwAUKADvlnAaHwgDx4K+vFxqbx8+5Lt1dZntN26MbLsAOKCmXOps1/Ah363LbH+IAgCMlSNBb9vShg1Db5OgzqDL169nMC4Q1Wxb+nToAjBoH99PAQDGypGgP35cOngweH+NC3zDn6zPNVN7+6yzbbNfY6MTrQQQEaeOS20HNfCavOQPLGo4I7UOONi3zX5+CgAwFo4EfVvb4OvqNVWSFK8u7dC8AWEvSa2tkWoZgIjrDF4ATtvSmUDQ+yVdXxcs7CWdpgAAY+FI0KelDb5ugd7Qh7pMknSujgUN+/T0SLYOQEQlBC8AiZb05jRpYqAKvXdykLBPpAAAY+FI0OfkSAUFkmUNXHdC2Zo/SNhbltkvO9uJVgKIiOQcKa1A0sACUJQibRs07C2zXxIFABgLR4LesqTlywdf3z/sM9Sic3VUkrRiRfAvCACihGVJFw5eAPqH/dEzUkv3Uf1FFABgrBy7va60VEpNleIG+cTusN+pq3SjtuqduHlKTZXuvtupFgKImPxSKSFVg5Wc7rD/SrK0Y5o0LSHObD+DAgCMlWNBn5UlbdlivpwPFfb/S+/orbjrZFlSRYXZD0CUS8qSrgoUgCHCfvd0aXpinNnuaxVmPwBj4ugUuMXFUmWl5POZftz/jJxZZsnnk6qqpAULAitWr5b2DhyNDyCK5BZLV1dKCT6Z6/X9T8lbsizLrL+mSpq6QCc7T+rBNx9U6ylG3gOj5fiP2hQXS4cPS2vXSvn5fdfl55vldXW9Qv6RR6T775fmzSPsgWiXWywtPizNWiul9SsAaflm+eK6npBf/Pxi/fS9n+r6TdcT9sAoWbY9/LRTLS0tyszMVHNzszIyMsL24bZtJsNpbTW30GVn9zvK7+iQrrpK2rPHvJ4yRdqxQ7r44rC1AYhmkeqbjnyGbZvJcE63mlvokvoWgH0N+zT3mbk6cfKEJOmr07+qV7/1qtKTud0OkELvm678Hn03yzK33p1/vnkeMLjW55PeeEO6zIzG17FjHNkDXmFZgVvvzjfP/QrAzEkzte3ubZqYMlGS9N5n73FkD4yCq0Efkuxswh6IUUVTiwh7YIzGf9BLhD0Qwwh7YGyiI+glwh6IYYQ9MHrRE/RS8LC/805+xhKIAcHC/pG3HnG3UUAUiK6gl/qGfW6u9PvfM0UmECN6h/3V512tH8/7sdtNAsa9BLcbMCrdYd/YKF1wgdutAeCgoqlFenfZuzov8zxNSJrgdnOAcS/6jui7ZWcPDPnOTqm21pXmAHDOJZMvGRDyx9qOcc0eCCJ6g76/zk7pjjukK69kgB4QY462HdW88nkM0AOC8E7Q//M/S5s3MxofiDG2bWvJ5iXa27CX0fhAEN4J+pUrufUOiEGWZWn9N9Zz6x0wCO8EPffZAzGL++yBwXkn6CXCHohhhD0QnLeCXiLsgRhG2AMDjeg++szMzEi1I+wmSnpD0izpbNi/84504YXuNgyIUtHU/3WupFJJvrNh//pdrys1MdXtlgGO894RfcAJSfOls0f2eXnS5MkutgiAY45KKlfPkf3Fky5WSkKKu20CXOLZoJdM2OuNN6Rly8zzxIluNwmAU45K2+7eplVXrtK/3fhvirM8Xe6AQUXnFLgjkZ0tPfOM260A4IKiqUUqmlrkdjMAV8XmV9wTJ6QbbmCAHhCDPj76sW5+/mYG6CFmxF7QnzghLVggVVYyGh+IMR8f/VjXbrxWL+9/mdH4iBmxF/SS1NVlnrn1DogpXXaXbNuWxK13iB2xF/QTJ3KfPRCjuM8esSj2gl5iUh0ghhH2iDWxGfQSYQ/EMMIesSR2g14i7IEYRtgjVsR20EvBw37DBnfbBMARwcK+6kCVy60Cwougl/qG/ZIl0rp1brcIgEO6wz7bl621xWu19K+Wut0kIKy8PzNeqLKzpW3bpAkTpMREt1sDwEFFU4u0/wf7NSl1kttNAcKOI/resrIGhvyBA1yzB2JAsJDfcWgH1+wR9Qj6oRw4IF1zzYABerYtNTRItbXmOTD/BgAP+Y99/6EFv1swcICebUsnG6S2WvNMAcA4R9AP5R/+Qaqv7xmN37J7r9atkwoLzS/ezphhngsLzWX9pia3GwwgHL7wf6G/e+Xv1NnVeXY0futn0r510tZCqWKy9PIM87y10Cz3N7ndbCAoy7aH/zra0tKizMxMJ9oTdiH8e4NrbJTmz5f27JEkHbOmaJ69Q/usi/t8ibcs85yaKm3ZIhUXj6HBwAh0983m5mZlZGRE9DOi0Vj6/0dHPtJ1G6/TiZMnJElf9cXp1dwupcdZknq/b6AAJKRKV22RcikAcEao/Z8j+qEERuM3X2BuvZtiH9N2zdNFdt9r9rZtHh0d0qJFUnW1G40FEE49t94lp0mS3uvo0vV1UmtX/y8Ptnl0dkhvL5LqKQAYXwj6YTTFZeuv6t/QhzJhf66OaYfmaaYGDtDr6jKBX1LCaXzAC4pyZmhbbqcmBirleycVCPtgWwcKwLslnMbHuELQD6O8XKrryNZ8hR727e3Sxo1OtxRA2NWUqyjhlLZNU+hh39kuHaIAYPwg6Idg22cnyTuh4GE/SZ8H3Xf9egbjAlHNtqVPTQEoStGAsL+lfog+vp8CgPGDoB/C8ePSwYNn+2t32B9WriTpRd2iBk0esJ9tm/0aG51sLYCwOnVcajuo7oF3RSnSa9OkRJnhd/dknh2I25dt9vNTADA+EPRDaGsbuOxv9SvlqV6StESbBz2il6RW5tkAoldn3wLgt6X/2yidlon+nzcPc9B+mgKA8YGgH0JaWt/XD6hMZfrHnterdV/QI/pu6emRahmAiEs4WwD8tnTrEWnrF+a1z5Iezh7siD4gkQKA8YGgH0JOjlRQYDpz/5B/UI/rp3ow6H6WZfbLznaqpQDCLjlHSisIGvKv5ErXpg62oyWlFUhJFACMDwT9ECxLWr5cyrSbdK9+0bN8qJDvtmLFMN/2AYxvliVduFwfnpReCznkAy6iAGD8IOiHUVoqnZ6QpWutt/SZ8oYN+bg4M0Pe3Xc72EgAkZFfqjnpE1Qx1VJWXCghH2dmyJtBAcD4wc/UDiMry0xru2hRgb7c9YlO2FmDbhsXZ77EV1SY/QBEuaQs6aotuuHtRTrk61JW/FCj7wIF4GsVZj9gnOCIfjAVFZLfL8nMXV9ZKflTs2RZA8/IdS/z+aSqKmnBAhfaCyAs/Gf8enHvi2cX5BZLV1cqKzlV5sa6/qfkA8sSfNI1VdJUCgDGF4I+mLIyM4/t7bf3CfvDh6W1a6X8/L6b5+eb5XV1hDwQzfxn/Lr132/VN//9m1r9x9VnV+QWS4sPS7PWSmn9CkBavlm+uI6Qx7jEr9f1V1Ym/ePZ0fXaskX65jf7vaeZDKe11dxClz3cbTZAhPDrdUMbSf/vDvmtn26VJPkSfNr/g/2anjm9/5uayXBOt5pb6JIoAHBHqP2fa/S99Q/5xx8fEPKS6dM5OeYBIPoFC/lX7nhlYMhLpgAk55gHEAU4dd8tWMg/OPQtdACi32Ahf+2Ma11uGRAeBL1EyAMxipBHLCDoCXkgJhHyiBWxHfTl5YQ8EKPueeUeQh4xIbaDfvFi6YorzN+EPBBTVl65UpNSJxHy8LzYHnWfmSm9/rr00ktmrlsAMePSKZdq+93b1dDeoHkz5rndHCBiYi/oT56UUlLOvs7MJOSBGOA/41e8Fa/4uPieZZdOudTFFgHOiK1T92Vl0pw50vHjbrcEgIO6B959b+v3dKbrjNvNARwVO0f0vUfXf/3r0q5dfY/sAXhS/9H1KfEp+tcb/tXlVgHOiY0j+v630C1dSsgDMSDYLXRLvrTE5VYBzvJ+0HOfPBCb4sV98oA8HvQPSIQ8EIviJd0mQh6Qh4P+AUllvRcQ8kBsCIS8LjIvCXnEuhEFfXNzs2zbHv+Pxx8n5IEwi4b+f6rzlG787Y2EPNCL947obVv6z/88+5qQB2JGy6kW1ZyokUTIA928d3udZUkbN5q///qvCXkghkxKnaTtpdt1w3M3qOzrZYQ8IC8GvSQlJEibNpnQBxBTzplwjnZ/b7cs+j8gySun7jdskPbt67uMTg54nv+MXw/veFht/rY+ywl54KzoD/qyMmnFCmnevIFhD8CzuifDefSdR3X9pusHhD0AI7qDvvdkOEePSm++6W57ADii/4x3H9Z/qP/+y3+73CpgfIreoO8/411ZmfSDH7jXHgCOCDatbeUdlZqdN9vllgHjU3QGfbCQf+AB99oDwBGDhTy/Jw8MLvqCnpAHYhIhD4xOdAU9IQ/EJEIeGL3oCfo//pGQB2LUk398kpAHRil6gn7uXOnRR83fhDwQU1bNWaWFhQsJeWAUomtmvH/6J+m666Q5c9xuCQAHJSckq+K2Cv3XX/5Ls3Jnud0cIKqM7yP62tqBywh5wPP8Z/yqb63vsyw5IZmQB0bB1aC3bamhweR5Q4N53aOsTLr4Yun1191qHoBIsm3pZIPUVmueAwWge+DdVf/vKv1P0/+420bAA1w5dd/UJJWXmynqDx48u7ygQFq+XPrbxjL5fhwYeHfzzWZq2/POc6OpAMLN3yTVlEufbpDaehWAtAL5C/5et/7pTW3982uSpEXPLdLH93ys+Lh4d9oKeIDjQV9dLZWUSO3tA9fV1EhH/3eZfOo1uv6RRwh5wCvqq6V3S6TOgQXA33pQt756n7Z+YV77EnzacP0GQh4YI0dP3VdXS4sWSR0d5ixdn1P1kv6PXabHe4X8p8sYXQ94Rn219PYiqbNDkh14GH5buvWIzoa8JVUWP8LoeiAMHAv6piZzJG/bUlfXwPUPqExlvUL+QatMl73wgJqanGohgIjxN5kjeduW1LcABA35XEvzan5s9gMwJo4FfXm5OV0fSsg/oDL91H5A7e3Sxo1OtRBAxNSUB07XhxLy0rxU22x/iAIAjJUjQW/bZuBdMPfriQEh/4TOnq5fv37gKX4AUcS2zcC7fk4PGvK9NtpPAQDGypGgP37cjK4P1l8PqkCnA2MC+4e8bZv9GhudaCWAiDh1PDC6vm8BSJBUmGj+Dhryss1+fgoAMBaOjLpvaxt8XYVKdLueV75qtFr3B92mtVXKyYlQ4wBEVmfwAmBZ0upJUrIlzU/tH/K9nG6VkikAwGg5EvRpaUOvr1DJkOvT08PYGADOShi8AFiW9JNJw+yfSAEAxsKRU/c5OWYyHMsa2X6WZfbLzo5MuwA4IDlHSiuQNMICIMvsl0QBAMbCkaC3LDPj3WisWDHyLwgAxhHLki4cZQG4iAIAjJVjt9eVlkqpqVJciJ8YF2e2v/vuyLYLgAPyS6WEVIVecuLM9jMoAMBYORb0WVnSli3my/lwYR8XZ7arqDD7AYhySVnSVYECMGzZCRSAr1WY/QCMiaNT4BYXS5WVks9n+nH/M3Ldy3w+qapKWrDAydYBiKjcYunqSinBJ3O9vv8p+cCyBJ90TZU0lQIAhIPjP1NbXCwdPiytXSvl5/ddl59vltfVEfKAJ+UWS4sPS7PWSmn9CkBavlm+uI6QB8LIsu3hp51qaWlRZmammpublZGREbYPt20zGU5rq7mFLjubcTfASESqbzryGbZtJsM53WpuoUuiAAAjEWrfdOX36LtZlrn1jslwgBhkWebWOybDASLK8VP3AADAOQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQAAHkbQAwDgYQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQAAHhbSj9p0/8BdS0tLRBsDYGS6+2QIP0I5avR/YHwKtf+HFPStra2SpOnTp4+xWQAiobW1VZmZmRF7b4n+D4xXw/X/kH6PvqurS/X19UpPT5fF70UD44Zt22ptbVVubq7i4iJzJY7+D4xPofb/kIIeAABEJwbjAQDgYQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQAAHkbQAwDgYf8faKzyfSsCZ7UAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 630x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:26:24: Training set row 2 with\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Training set row 2 with\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Y_true [[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAESCAYAAAAVAhemAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAe/klEQVR4nO3df3RU9Z3/8dfN7wn5RQIiIRwlMYp23Z6IFaH2q2ghFfyBjYhr1bS0Z9ethfOF1a/ucWvd+rWmFll+tF231a8NLVaXEl0x0aiAihY5R7GuuweQErJHEqCGkF8mMITc7x+fSciPSTJJZu7N3Hk+zpkzmftj5pM/Pu/X3Hs/9zOWbdu2AACAJ8W53QAAABA5BD0AAB5G0AMA4GEEPQAAHkbQAwDgYQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQBgTCzL6nn85je/cbs56IegH6fOP//8Pp0nlMdbb73ldrMBhMFbb701aD9PS0vTJZdcouXLl6umpsbtpiIKEPQAEEW++OIL7d27Vz//+c916aWX6s0333S7SRjnEtxuAIJ76KGH1Nzc3PP6xIkT+slPftLzev78+VqwYEGffQoKCoK+V0tLizIyMiLTUAARt3TpUl1++eXy+/3atWuXXnnlFUlSe3u77rrrLtXW1io5OXnI96AOxDAbUeHQoUO2pJ7Hj370o0HX7dixw3766aftoqIiOyUlxf7yl79s27Ztl5aW9mxz9dVX93n/HTt29HmPQ4cO9Vl/5swZe+PGjfb8+fPtyZMn24mJifakSZPshQsX2pWVlZH954EY078/Pvvss33Wf+tb3+qzftu2bQP2OXDggP2zn/3Mnjlzpp2UlGTffPPNPfuPpj+fPn3afvzxx+0LLrjATkpKsvPz8+1HH33U9vv9Q7YV7uOI3oMefvhh7dy5M2zv19HRoZtuumnAKcKGhgZVVVWpqqpKq1at0pNPPhm2zwQwuDlz5mjTpk09r48eParc3Nw+2yxbtixoHRhtf77rrrv0/PPP97yuqanRD3/4Q73//vvh+JcQQQS9B+3cuVPnnXeeSkpKlJqaqr/85S9jer+VK1f2FIWkpCTdfvvtKiws1CeffKLNmzfLtm2tWbNGs2bN0h133BGOfwHAEHbt2tXn9bnnnjtgm507d+pLX/qSbrzxRtm2rfj4eEmj689/+MMf+oT8BRdcoNtuu011dXX67W9/G6l/E2FC0HvQjBkztGfPHmVlZY35vRobG/XMM8/0vH7qqaf0ne98p+f1pEmT9Mtf/lKStHr1aoIeiIDXXntNDQ0N8vv9ev/997V169aedVOmTNHcuXMHHFlfeeWV2rFjh1JSUnqWjbY/P/300z3bZGZmavfu3crOzpYkXXjhhXrooYfC+N8i3Ah6D7r33nvDEvKStHv3bnV2dva8XrZsmZYtWxZ02z/96U9qb29XampqWD4bgPHCCy/ohRdeGLA8JSVF5eXlfcK823333Tdg+Wj78wcffNCz/Bvf+EZPyEvSnXfeSdCPc9xe50EzZ84cdhvbtvu8PnXqVNDtGhsbQ/5c27Z1/PjxkLcHMHI+n08zZ87U97//fX3yyScqLi4Oul2wOjDa/tzU1NSz/Jxzzumz3ZQpU0J+T7iDI3oPmjBhQtDlcXFnv9d1dHT0WXfgwIGg+/T+5i6Z63v9B/30lpmZGWozAYTo2Wef1be//e0R7ROsDoy2P2dlZfWEfv8xP8eOHRtRu+A8gj6G9D6dv3//fjU1NSkrK0vNzc36xS9+EXSf2bNnKz4+XmfOnJEkJSYm6r777huwXW1trfbv3899usA4Ntr+fPnll6u6ulqSGS/Q2NjY86Xhd7/7nUOtx2gR9DHkK1/5Ss/fLS0tKioq0hVXXKH33ntPdXV1QffJzs7WsmXL9Otf/1qS9MQTT+iDDz7Q3LlzlZKSorq6Or3//vv66KOPVFpaOuhpRADuG21//u53v9sT9M3NzZo9e7aWLl2qw4cPM+o+ChD0MeSWW25RYWFhz2n62tpa1dbWSpIWLlyoqqqqoPutXbtWhw4d6rklZ/v27dq+fbsjbQYQXqPpz0uWLNGSJUu0efNmSdKf//xnPfbYY5Kka665ht/ZGOcYjBdDUlJStG3bNt12223KyspSSkqKZs+erRdffFH333//oPulpqaqurpazz33nBYuXKgpU6YoISFBPp9PBQUFuvXWW/WrX/1Ka9ascfC/ATAao+3PmzZt0mOPPab8/HwlJibq/PPP10MPPaRXX33Vpf8EobLs/sOvAQCAZ3BEDwCAhxH0AAB4GEEPAICHEfQAAHgYQQ8AgIcR9AAAeFhIE+Z0dXWpvr5e6enpsiwr0m0CECLbttXa2qrc3Nw+v2UQTvR/YHwKtf+HFPT19fWaPn162BoHILw+++wz5eXlReS96f/A+DZc/w8p6NPT03vejB8tAcaPlpYWTZ8+vaePRgL9HxifQu3/IQV99+m6jIwMOjowDkXylDr9Hxjfhuv/DMYDAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPCzBzQ+3ben4camtTUpLk3JyJMtys0UAHGPb0qnjUmeblJAmJVMAgEhw5Yi+qUlat04qLJQmT5ZmzDDPhYVmeVOTG60C4Ah/k7RvnbS1UKqYLL08wzxvLTTL/U1utxDwFMeDvrpaysuTVq6Uamr6rqupMcvz8sx2ADymvlp6KU/as1Jq61cA2mrM8pfyzHYAwsLRoK+ulhYtkjo6zFk72+67vntZR4fZjrAHPKS+Wnp7kdTZIckOPHoLLOvsMNsR9kBYOBb0TU1SSYkJ8q6uobft6jLblZRwGh/wBH+T9G6gAGiYAqBAAXi3hNP4QBg4FvTl5VJ7+/Ah362ry2y/cWNk2wXAATXlUme7hg/5bl1m+0MUAGCsHAl625Y2bBjdvuvXDzzFDyCK2Lb06SgLwH4KADBWjgT98ePSwYMj76+2bfZrbIxMuwA44NRxqe2gBl6TH45t9vNTAICxcOQ++ra2wdet1BplqEUtytC/aFXQbVpbzT32AKJQ5+AFYM0JqaVLyoiTVk0cZKPTreYeewCj4kjQp6UNvm6V1ihPdTqsaYMGfXp6hBoGIPISBi8Aa5qkuk5pWsIQQZ9IAQDGwpFT9zk5UkHByCe9siyzX3Z2ZNoFwAHJOVJagaSRznpnmf2SKADAWDhyRG9Z0vLlZjKc/u7RU/KpQx3yBd13xQpmxQSimmVJFy43k+H089RkqcOWfIP18YsoAMBYWbY9/BC5lpYWZWZmqrm5WRkZGaP6oKYmM+NdR0dot9jFxUk+n3T4sJSVNaqPBDwvHH3Tkc/wN5kZ7zo7FNotdnFSgk9afFhKyhrdZwIeF2rfdOw++qwsacsW8+U8bphPjYsz21VUEPKAJyRlSVcFCsCwZSdQAL5WQcgDYeDoFLjFxVJlpTlSt6yBZ+S6l/l8UlWVtGCBk60DEFG5xdLVleZIXZYGXrMPLEvwSddUSVMpAEA4OP4ztcXF5nT8xo1mMpzMgx8qSX75laTm/FlasUIqLZUyM51uGYCIyy02p+MPbZT2r9eHDQflt6UkS5o1Kd9ck59RKiVRAIBwcewafTC2LXVNy1P8kTqdmTpNcXWHGXcDjEDUXKMPxraV9y/TVNd6RNPSp+rwyjoG3gEjEGrfdPyIvjfLkuIDFw/i4zTyu28ARK8+1+vjCHkgQhz/PXoAAOAcgh4AAA8j6AEA8DCCHgAADyPoAQDwMIIeAAAPI+gBAPAwgh4AAA9zdcIcSdLevWaKPCbLAGLO3nv3ypYti9mygIhxP+jT091uAQCXpCfT/4FI49Q9AAAeRtADAOBh7p+6X7NGammRMjKkVavcbg0AB63ZtUYtp1qUkZyhVXPo/0AkjI+gr6uTpk0j6IEYs2bXGtW11mla+jSCHogQTt0DAOBhBD0AAB5G0AMA4GEEPQAAHkbQAwDgYQQ9AAAeRtADAOBhBD0AAB7m/oQ5l10mTZ8uTZ7sdksAOOyyqZdpeuZ0TU6l/wOR4n7Qv/yy2y0A4JKX/4b+D0Qap+4BAPAwgh4AAA8j6AEA8DD3r9HfdJP0+edmMB7X64GYctPvb9Ln7Z9rcupkrtcDEeJ+0O/Zc/ZnagHElD1H9vT8TC2AyHD11L1tS2e6zN9nusxrADHCtiU7UABsCgAQKa4EfVOTtG6dVFgoHTlilh05Yl6vW2fWA/Aof5O0b520tVA6GSgAJ4+Y1/vWmfUAwsbxoK+ulvLypJUrpZqavutqaszyvDyzHQCPqa+WXsqT9qyU2voVgLYas/ylPLMdgLBwNOirq6VFi6SOjsBZu35n6rqXdXSY7Qh7wEPqq6W3F0mdHZLswKO3wLLODrMdYQ+EhWNB39QklZSYIO/qGnrbrsDlupISTuMDnuBvkt4NFAANUwAUKADvlnAaHwgDx4K+vFxqbx8+5Lt1dZntN26MbLsAOKCmXOps1/Ah363LbH+IAgCMlSNBb9vShg1Db5OgzqDL169nMC4Q1Wxb+nToAjBoH99PAQDGypGgP35cOngweH+NC3zDn6zPNVN7+6yzbbNfY6MTrQQQEaeOS20HNfCavOQPLGo4I7UOONi3zX5+CgAwFo4EfVvb4OvqNVWSFK8u7dC8AWEvSa2tkWoZgIjrDF4ATtvSmUDQ+yVdXxcs7CWdpgAAY+FI0KelDb5ugd7Qh7pMknSujgUN+/T0SLYOQEQlBC8AiZb05jRpYqAKvXdykLBPpAAAY+FI0OfkSAUFkmUNXHdC2Zo/SNhbltkvO9uJVgKIiOQcKa1A0sACUJQibRs07C2zXxIFABgLR4LesqTlywdf3z/sM9Sic3VUkrRiRfAvCACihGVJFw5eAPqH/dEzUkv3Uf1FFABgrBy7va60VEpNleIG+cTusN+pq3SjtuqduHlKTZXuvtupFgKImPxSKSFVg5Wc7rD/SrK0Y5o0LSHObD+DAgCMlWNBn5UlbdlivpwPFfb/S+/orbjrZFlSRYXZD0CUS8qSrgoUgCHCfvd0aXpinNnuaxVmPwBj4ugUuMXFUmWl5POZftz/jJxZZsnnk6qqpAULAitWr5b2DhyNDyCK5BZLV1dKCT6Z6/X9T8lbsizLrL+mSpq6QCc7T+rBNx9U6ylG3gOj5fiP2hQXS4cPS2vXSvn5fdfl55vldXW9Qv6RR6T775fmzSPsgWiXWywtPizNWiul9SsAaflm+eK6npBf/Pxi/fS9n+r6TdcT9sAoWbY9/LRTLS0tyszMVHNzszIyMsL24bZtJsNpbTW30GVn9zvK7+iQrrpK2rPHvJ4yRdqxQ7r44rC1AYhmkeqbjnyGbZvJcE63mlvokvoWgH0N+zT3mbk6cfKEJOmr07+qV7/1qtKTud0OkELvm678Hn03yzK33p1/vnkeMLjW55PeeEO6zIzG17FjHNkDXmFZgVvvzjfP/QrAzEkzte3ubZqYMlGS9N5n73FkD4yCq0Efkuxswh6IUUVTiwh7YIzGf9BLhD0Qwwh7YGyiI+glwh6IYYQ9MHrRE/RS8LC/805+xhKIAcHC/pG3HnG3UUAUiK6gl/qGfW6u9PvfM0UmECN6h/3V512tH8/7sdtNAsa9BLcbMCrdYd/YKF1wgdutAeCgoqlFenfZuzov8zxNSJrgdnOAcS/6jui7ZWcPDPnOTqm21pXmAHDOJZMvGRDyx9qOcc0eCCJ6g76/zk7pjjukK69kgB4QY462HdW88nkM0AOC8E7Q//M/S5s3MxofiDG2bWvJ5iXa27CX0fhAEN4J+pUrufUOiEGWZWn9N9Zz6x0wCO8EPffZAzGL++yBwXkn6CXCHohhhD0QnLeCXiLsgRhG2AMDjeg++szMzEi1I+wmSnpD0izpbNi/84504YXuNgyIUtHU/3WupFJJvrNh//pdrys1MdXtlgGO894RfcAJSfOls0f2eXnS5MkutgiAY45KKlfPkf3Fky5WSkKKu20CXOLZoJdM2OuNN6Rly8zzxIluNwmAU45K2+7eplVXrtK/3fhvirM8Xe6AQUXnFLgjkZ0tPfOM260A4IKiqUUqmlrkdjMAV8XmV9wTJ6QbbmCAHhCDPj76sW5+/mYG6CFmxF7QnzghLVggVVYyGh+IMR8f/VjXbrxWL+9/mdH4iBmxF/SS1NVlnrn1DogpXXaXbNuWxK13iB2xF/QTJ3KfPRCjuM8esSj2gl5iUh0ghhH2iDWxGfQSYQ/EMMIesSR2g14i7IEYRtgjVsR20EvBw37DBnfbBMARwcK+6kCVy60Cwougl/qG/ZIl0rp1brcIgEO6wz7bl621xWu19K+Wut0kIKy8PzNeqLKzpW3bpAkTpMREt1sDwEFFU4u0/wf7NSl1kttNAcKOI/resrIGhvyBA1yzB2JAsJDfcWgH1+wR9Qj6oRw4IF1zzYABerYtNTRItbXmOTD/BgAP+Y99/6EFv1swcICebUsnG6S2WvNMAcA4R9AP5R/+Qaqv7xmN37J7r9atkwoLzS/ezphhngsLzWX9pia3GwwgHL7wf6G/e+Xv1NnVeXY0futn0r510tZCqWKy9PIM87y10Cz3N7ndbCAoy7aH/zra0tKizMxMJ9oTdiH8e4NrbJTmz5f27JEkHbOmaJ69Q/usi/t8ibcs85yaKm3ZIhUXj6HBwAh0983m5mZlZGRE9DOi0Vj6/0dHPtJ1G6/TiZMnJElf9cXp1dwupcdZknq/b6AAJKRKV22RcikAcEao/Z8j+qEERuM3X2BuvZtiH9N2zdNFdt9r9rZtHh0d0qJFUnW1G40FEE49t94lp0mS3uvo0vV1UmtX/y8Ptnl0dkhvL5LqKQAYXwj6YTTFZeuv6t/QhzJhf66OaYfmaaYGDtDr6jKBX1LCaXzAC4pyZmhbbqcmBirleycVCPtgWwcKwLslnMbHuELQD6O8XKrryNZ8hR727e3Sxo1OtxRA2NWUqyjhlLZNU+hh39kuHaIAYPwg6Idg22cnyTuh4GE/SZ8H3Xf9egbjAlHNtqVPTQEoStGAsL+lfog+vp8CgPGDoB/C8ePSwYNn+2t32B9WriTpRd2iBk0esJ9tm/0aG51sLYCwOnVcajuo7oF3RSnSa9OkRJnhd/dknh2I25dt9vNTADA+EPRDaGsbuOxv9SvlqV6StESbBz2il6RW5tkAoldn3wLgt6X/2yidlon+nzcPc9B+mgKA8YGgH0JaWt/XD6hMZfrHnterdV/QI/pu6emRahmAiEs4WwD8tnTrEWnrF+a1z5Iezh7siD4gkQKA8YGgH0JOjlRQYDpz/5B/UI/rp3ow6H6WZfbLznaqpQDCLjlHSisIGvKv5ErXpg62oyWlFUhJFACMDwT9ECxLWr5cyrSbdK9+0bN8qJDvtmLFMN/2AYxvliVduFwfnpReCznkAy6iAGD8IOiHUVoqnZ6QpWutt/SZ8oYN+bg4M0Pe3Xc72EgAkZFfqjnpE1Qx1VJWXCghH2dmyJtBAcD4wc/UDiMry0xru2hRgb7c9YlO2FmDbhsXZ77EV1SY/QBEuaQs6aotuuHtRTrk61JW/FCj7wIF4GsVZj9gnOCIfjAVFZLfL8nMXV9ZKflTs2RZA8/IdS/z+aSqKmnBAhfaCyAs/Gf8enHvi2cX5BZLV1cqKzlV5sa6/qfkA8sSfNI1VdJUCgDGF4I+mLIyM4/t7bf3CfvDh6W1a6X8/L6b5+eb5XV1hDwQzfxn/Lr132/VN//9m1r9x9VnV+QWS4sPS7PWSmn9CkBavlm+uI6Qx7jEr9f1V1Ym/ePZ0fXaskX65jf7vaeZDKe11dxClz3cbTZAhPDrdUMbSf/vDvmtn26VJPkSfNr/g/2anjm9/5uayXBOt5pb6JIoAHBHqP2fa/S99Q/5xx8fEPKS6dM5OeYBIPoFC/lX7nhlYMhLpgAk55gHEAU4dd8tWMg/OPQtdACi32Ahf+2Ma11uGRAeBL1EyAMxipBHLCDoCXkgJhHyiBWxHfTl5YQ8EKPueeUeQh4xIbaDfvFi6YorzN+EPBBTVl65UpNSJxHy8LzYHnWfmSm9/rr00ktmrlsAMePSKZdq+93b1dDeoHkz5rndHCBiYi/oT56UUlLOvs7MJOSBGOA/41e8Fa/4uPieZZdOudTFFgHOiK1T92Vl0pw50vHjbrcEgIO6B959b+v3dKbrjNvNARwVO0f0vUfXf/3r0q5dfY/sAXhS/9H1KfEp+tcb/tXlVgHOiY0j+v630C1dSsgDMSDYLXRLvrTE5VYBzvJ+0HOfPBCb4sV98oA8HvQPSIQ8EIviJd0mQh6Qh4P+AUllvRcQ8kBsCIS8LjIvCXnEuhEFfXNzs2zbHv+Pxx8n5IEwi4b+f6rzlG787Y2EPNCL947obVv6z/88+5qQB2JGy6kW1ZyokUTIA928d3udZUkbN5q///qvCXkghkxKnaTtpdt1w3M3qOzrZYQ8IC8GvSQlJEibNpnQBxBTzplwjnZ/b7cs+j8gySun7jdskPbt67uMTg54nv+MXw/veFht/rY+ywl54KzoD/qyMmnFCmnevIFhD8CzuifDefSdR3X9pusHhD0AI7qDvvdkOEePSm++6W57ADii/4x3H9Z/qP/+y3+73CpgfIreoO8/411ZmfSDH7jXHgCOCDatbeUdlZqdN9vllgHjU3QGfbCQf+AB99oDwBGDhTy/Jw8MLvqCnpAHYhIhD4xOdAU9IQ/EJEIeGL3oCfo//pGQB2LUk398kpAHRil6gn7uXOnRR83fhDwQU1bNWaWFhQsJeWAUomtmvH/6J+m666Q5c9xuCQAHJSckq+K2Cv3XX/5Ls3Jnud0cIKqM7yP62tqBywh5wPP8Z/yqb63vsyw5IZmQB0bB1aC3bamhweR5Q4N53aOsTLr4Yun1191qHoBIsm3pZIPUVmueAwWge+DdVf/vKv1P0/+420bAA1w5dd/UJJWXmynqDx48u7ygQFq+XPrbxjL5fhwYeHfzzWZq2/POc6OpAMLN3yTVlEufbpDaehWAtAL5C/5et/7pTW3982uSpEXPLdLH93ys+Lh4d9oKeIDjQV9dLZWUSO3tA9fV1EhH/3eZfOo1uv6RRwh5wCvqq6V3S6TOgQXA33pQt756n7Z+YV77EnzacP0GQh4YI0dP3VdXS4sWSR0d5ixdn1P1kv6PXabHe4X8p8sYXQ94Rn219PYiqbNDkh14GH5buvWIzoa8JVUWP8LoeiAMHAv6piZzJG/bUlfXwPUPqExlvUL+QatMl73wgJqanGohgIjxN5kjeduW1LcABA35XEvzan5s9gMwJo4FfXm5OV0fSsg/oDL91H5A7e3Sxo1OtRBAxNSUB07XhxLy0rxU22x/iAIAjJUjQW/bZuBdMPfriQEh/4TOnq5fv37gKX4AUcS2zcC7fk4PGvK9NtpPAQDGypGgP37cjK4P1l8PqkCnA2MC+4e8bZv9GhudaCWAiDh1PDC6vm8BSJBUmGj+Dhryss1+fgoAMBaOjLpvaxt8XYVKdLueV75qtFr3B92mtVXKyYlQ4wBEVmfwAmBZ0upJUrIlzU/tH/K9nG6VkikAwGg5EvRpaUOvr1DJkOvT08PYGADOShi8AFiW9JNJw+yfSAEAxsKRU/c5OWYyHMsa2X6WZfbLzo5MuwA4IDlHSiuQNMICIMvsl0QBAMbCkaC3LDPj3WisWDHyLwgAxhHLki4cZQG4iAIAjJVjt9eVlkqpqVJciJ8YF2e2v/vuyLYLgAPyS6WEVIVecuLM9jMoAMBYORb0WVnSli3my/lwYR8XZ7arqDD7AYhySVnSVYECMGzZCRSAr1WY/QCMiaNT4BYXS5WVks9n+nH/M3Ldy3w+qapKWrDAydYBiKjcYunqSinBJ3O9vv8p+cCyBJ90TZU0lQIAhIPjP1NbXCwdPiytXSvl5/ddl59vltfVEfKAJ+UWS4sPS7PWSmn9CkBavlm+uI6QB8LIsu3hp51qaWlRZmammpublZGREbYPt20zGU5rq7mFLjubcTfASESqbzryGbZtJsM53WpuoUuiAAAjEWrfdOX36LtZlrn1jslwgBhkWebWOybDASLK8VP3AADAOQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQAAHkbQAwDgYQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQAAHhbSj9p0/8BdS0tLRBsDYGS6+2QIP0I5avR/YHwKtf+HFPStra2SpOnTp4+xWQAiobW1VZmZmRF7b4n+D4xXw/X/kH6PvqurS/X19UpPT5fF70UD44Zt22ptbVVubq7i4iJzJY7+D4xPofb/kIIeAABEJwbjAQDgYQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQAAHkbQAwDgYf8faKzyfSsCZ7UAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 630x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "##==========================================##\n",
        "##  Plot some predictions on training data  ##\n",
        "##==========================================##\n",
        "\n",
        "num_print = min([3, len(train_X)])\n",
        "print(\"train_X\",train_X)\n",
        "train_Y_predictions = model.predict(train_X[:num_print], verbose=0)\n",
        "for row_idx in range(num_print) :\n",
        "    logger.info(f\"Training set row {row_idx} with\")\n",
        "    logger.debug(f\"Y_TRUE =\\n{train_Y[row_idx]}\\n\")\n",
        "    logger.debug(f\"Y_PRED =\\n{train_Y_predictions[row_idx]}\\n\")\n",
        "    plot_maps(train_Y[row_idx], train_Y_predictions[row_idx], train_X[row_idx])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "id": "VgsmffyE1FJ4",
        "outputId": "ede580f5-3113-4ef4-b806-31afb7d67be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   INFO 2023-11-28 10:26:29: Validationn set row 0 with\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:__main__:Validationn set row 0 with\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val_Y_predictions[row_idx] [[1.5386434e-04 9.9782574e-01 9.9559096e-05 9.8607175e-05 3.2976959e-04]\n",
            " [4.0685576e-05 7.4469681e-05 4.1957890e-05 3.1208219e-05 3.4991303e-05]\n",
            " [3.3955548e-05 6.3621184e-05 4.4045268e-05 3.7852704e-05 3.5829202e-05]\n",
            " [3.1796819e-05 1.0535962e-04 4.4460099e-05 4.6641027e-05 7.1366325e-05]\n",
            " [4.6436653e-05 7.5583630e-05 6.9888163e-05 5.5608376e-05 1.0352653e-04]]\n",
            "Y_true [[0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAESCAYAAAAVAhemAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAe/klEQVR4nO3df3RU9Z3/8dfN7wn5RQIiIRwlMYp23Z6IFaH2q2ghFfyBjYhr1bS0Z9ethfOF1a/ucWvd+rWmFll+tF231a8NLVaXEl0x0aiAihY5R7GuuweQErJHEqCGkF8mMITc7x+fSciPSTJJZu7N3Hk+zpkzmftj5pM/Pu/X3Hs/9zOWbdu2AACAJ8W53QAAABA5BD0AAB5G0AMA4GEEPQAAHkbQAwDgYQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQBgTCzL6nn85je/cbs56IegH6fOP//8Pp0nlMdbb73ldrMBhMFbb701aD9PS0vTJZdcouXLl6umpsbtpiIKEPQAEEW++OIL7d27Vz//+c916aWX6s0333S7SRjnEtxuAIJ76KGH1Nzc3PP6xIkT+slPftLzev78+VqwYEGffQoKCoK+V0tLizIyMiLTUAARt3TpUl1++eXy+/3atWuXXnnlFUlSe3u77rrrLtXW1io5OXnI96AOxDAbUeHQoUO2pJ7Hj370o0HX7dixw3766aftoqIiOyUlxf7yl79s27Ztl5aW9mxz9dVX93n/HTt29HmPQ4cO9Vl/5swZe+PGjfb8+fPtyZMn24mJifakSZPshQsX2pWVlZH954EY078/Pvvss33Wf+tb3+qzftu2bQP2OXDggP2zn/3Mnjlzpp2UlGTffPPNPfuPpj+fPn3afvzxx+0LLrjATkpKsvPz8+1HH33U9vv9Q7YV7uOI3oMefvhh7dy5M2zv19HRoZtuumnAKcKGhgZVVVWpqqpKq1at0pNPPhm2zwQwuDlz5mjTpk09r48eParc3Nw+2yxbtixoHRhtf77rrrv0/PPP97yuqanRD3/4Q73//vvh+JcQQQS9B+3cuVPnnXeeSkpKlJqaqr/85S9jer+VK1f2FIWkpCTdfvvtKiws1CeffKLNmzfLtm2tWbNGs2bN0h133BGOfwHAEHbt2tXn9bnnnjtgm507d+pLX/qSbrzxRtm2rfj4eEmj689/+MMf+oT8BRdcoNtuu011dXX67W9/G6l/E2FC0HvQjBkztGfPHmVlZY35vRobG/XMM8/0vH7qqaf0ne98p+f1pEmT9Mtf/lKStHr1aoIeiIDXXntNDQ0N8vv9ev/997V169aedVOmTNHcuXMHHFlfeeWV2rFjh1JSUnqWjbY/P/300z3bZGZmavfu3crOzpYkXXjhhXrooYfC+N8i3Ah6D7r33nvDEvKStHv3bnV2dva8XrZsmZYtWxZ02z/96U9qb29XampqWD4bgPHCCy/ohRdeGLA8JSVF5eXlfcK823333Tdg+Wj78wcffNCz/Bvf+EZPyEvSnXfeSdCPc9xe50EzZ84cdhvbtvu8PnXqVNDtGhsbQ/5c27Z1/PjxkLcHMHI+n08zZ87U97//fX3yyScqLi4Oul2wOjDa/tzU1NSz/Jxzzumz3ZQpU0J+T7iDI3oPmjBhQtDlcXFnv9d1dHT0WXfgwIGg+/T+5i6Z63v9B/30lpmZGWozAYTo2Wef1be//e0R7ROsDoy2P2dlZfWEfv8xP8eOHRtRu+A8gj6G9D6dv3//fjU1NSkrK0vNzc36xS9+EXSf2bNnKz4+XmfOnJEkJSYm6r777huwXW1trfbv3899usA4Ntr+fPnll6u6ulqSGS/Q2NjY86Xhd7/7nUOtx2gR9DHkK1/5Ss/fLS0tKioq0hVXXKH33ntPdXV1QffJzs7WsmXL9Otf/1qS9MQTT+iDDz7Q3LlzlZKSorq6Or3//vv66KOPVFpaOuhpRADuG21//u53v9sT9M3NzZo9e7aWLl2qw4cPM+o+ChD0MeSWW25RYWFhz2n62tpa1dbWSpIWLlyoqqqqoPutXbtWhw4d6rklZ/v27dq+fbsjbQYQXqPpz0uWLNGSJUu0efNmSdKf//xnPfbYY5Kka665ht/ZGOcYjBdDUlJStG3bNt12223KyspSSkqKZs+erRdffFH333//oPulpqaqurpazz33nBYuXKgpU6YoISFBPp9PBQUFuvXWW/WrX/1Ka9ascfC/ATAao+3PmzZt0mOPPab8/HwlJibq/PPP10MPPaRXX33Vpf8EobLs/sOvAQCAZ3BEDwCAhxH0AAB4GEEPAICHEfQAAHgYQQ8AgIcR9AAAeFhIE+Z0dXWpvr5e6enpsiwr0m0CECLbttXa2qrc3Nw+v2UQTvR/YHwKtf+HFPT19fWaPn162BoHILw+++wz5eXlReS96f/A+DZc/w8p6NPT03vejB8tAcaPlpYWTZ8+vaePRgL9HxifQu3/IQV99+m6jIwMOjowDkXylDr9Hxjfhuv/DMYDAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPIygBwDAwwh6AAA8jKAHAMDDCHoAADyMoAcAwMMIegAAPCzBzQ+3ben4camtTUpLk3JyJMtys0UAHGPb0qnjUmeblJAmJVMAgEhw5Yi+qUlat04qLJQmT5ZmzDDPhYVmeVOTG60C4Ah/k7RvnbS1UKqYLL08wzxvLTTL/U1utxDwFMeDvrpaysuTVq6Uamr6rqupMcvz8sx2ADymvlp6KU/as1Jq61cA2mrM8pfyzHYAwsLRoK+ulhYtkjo6zFk72+67vntZR4fZjrAHPKS+Wnp7kdTZIckOPHoLLOvsMNsR9kBYOBb0TU1SSYkJ8q6uobft6jLblZRwGh/wBH+T9G6gAGiYAqBAAXi3hNP4QBg4FvTl5VJ7+/Ah362ry2y/cWNk2wXAATXlUme7hg/5bl1m+0MUAGCsHAl625Y2bBjdvuvXDzzFDyCK2Lb06SgLwH4KADBWjgT98ePSwYMj76+2bfZrbIxMuwA44NRxqe2gBl6TH45t9vNTAICxcOQ++ra2wdet1BplqEUtytC/aFXQbVpbzT32AKJQ5+AFYM0JqaVLyoiTVk0cZKPTreYeewCj4kjQp6UNvm6V1ihPdTqsaYMGfXp6hBoGIPISBi8Aa5qkuk5pWsIQQZ9IAQDGwpFT9zk5UkHByCe9siyzX3Z2ZNoFwAHJOVJagaSRznpnmf2SKADAWDhyRG9Z0vLlZjKc/u7RU/KpQx3yBd13xQpmxQSimmVJFy43k+H089RkqcOWfIP18YsoAMBYWbY9/BC5lpYWZWZmqrm5WRkZGaP6oKYmM+NdR0dot9jFxUk+n3T4sJSVNaqPBDwvHH3Tkc/wN5kZ7zo7FNotdnFSgk9afFhKyhrdZwIeF2rfdOw++qwsacsW8+U8bphPjYsz21VUEPKAJyRlSVcFCsCwZSdQAL5WQcgDYeDoFLjFxVJlpTlSt6yBZ+S6l/l8UlWVtGCBk60DEFG5xdLVleZIXZYGXrMPLEvwSddUSVMpAEA4OP4ztcXF5nT8xo1mMpzMgx8qSX75laTm/FlasUIqLZUyM51uGYCIyy02p+MPbZT2r9eHDQflt6UkS5o1Kd9ck59RKiVRAIBwcewafTC2LXVNy1P8kTqdmTpNcXWHGXcDjEDUXKMPxraV9y/TVNd6RNPSp+rwyjoG3gEjEGrfdPyIvjfLkuIDFw/i4zTyu28ARK8+1+vjCHkgQhz/PXoAAOAcgh4AAA8j6AEA8DCCHgAADyPoAQDwMIIeAAAPI+gBAPAwgh4AAA9zdcIcSdLevWaKPCbLAGLO3nv3ypYti9mygIhxP+jT091uAQCXpCfT/4FI49Q9AAAeRtADAOBh7p+6X7NGammRMjKkVavcbg0AB63ZtUYtp1qUkZyhVXPo/0AkjI+gr6uTpk0j6IEYs2bXGtW11mla+jSCHogQTt0DAOBhBD0AAB5G0AMA4GEEPQAAHkbQAwDgYQQ9AAAeRtADAOBhBD0AAB7m/oQ5l10mTZ8uTZ7sdksAOOyyqZdpeuZ0TU6l/wOR4n7Qv/yy2y0A4JKX/4b+D0Qap+4BAPAwgh4AAA8j6AEA8DD3r9HfdJP0+edmMB7X64GYctPvb9Ln7Z9rcupkrtcDEeJ+0O/Zc/ZnagHElD1H9vT8TC2AyHD11L1tS2e6zN9nusxrADHCtiU7UABsCgAQKa4EfVOTtG6dVFgoHTlilh05Yl6vW2fWA/Aof5O0b520tVA6GSgAJ4+Y1/vWmfUAwsbxoK+ulvLypJUrpZqavutqaszyvDyzHQCPqa+WXsqT9qyU2voVgLYas/ylPLMdgLBwNOirq6VFi6SOjsBZu35n6rqXdXSY7Qh7wEPqq6W3F0mdHZLswKO3wLLODrMdYQ+EhWNB39QklZSYIO/qGnrbrsDlupISTuMDnuBvkt4NFAANUwAUKADvlnAaHwgDx4K+vFxqbx8+5Lt1dZntN26MbLsAOKCmXOps1/Ah363LbH+IAgCMlSNBb9vShg1Db5OgzqDL169nMC4Q1Wxb+nToAjBoH99PAQDGypGgP35cOngweH+NC3zDn6zPNVN7+6yzbbNfY6MTrQQQEaeOS20HNfCavOQPLGo4I7UOONi3zX5+CgAwFo4EfVvb4OvqNVWSFK8u7dC8AWEvSa2tkWoZgIjrDF4ATtvSmUDQ+yVdXxcs7CWdpgAAY+FI0KelDb5ugd7Qh7pMknSujgUN+/T0SLYOQEQlBC8AiZb05jRpYqAKvXdykLBPpAAAY+FI0OfkSAUFkmUNXHdC2Zo/SNhbltkvO9uJVgKIiOQcKa1A0sACUJQibRs07C2zXxIFABgLR4LesqTlywdf3z/sM9Sic3VUkrRiRfAvCACihGVJFw5eAPqH/dEzUkv3Uf1FFABgrBy7va60VEpNleIG+cTusN+pq3SjtuqduHlKTZXuvtupFgKImPxSKSFVg5Wc7rD/SrK0Y5o0LSHObD+DAgCMlWNBn5UlbdlivpwPFfb/S+/orbjrZFlSRYXZD0CUS8qSrgoUgCHCfvd0aXpinNnuaxVmPwBj4ugUuMXFUmWl5POZftz/jJxZZsnnk6qqpAULAitWr5b2DhyNDyCK5BZLV1dKCT6Z6/X9T8lbsizLrL+mSpq6QCc7T+rBNx9U6ylG3gOj5fiP2hQXS4cPS2vXSvn5fdfl55vldXW9Qv6RR6T775fmzSPsgWiXWywtPizNWiul9SsAaflm+eK6npBf/Pxi/fS9n+r6TdcT9sAoWbY9/LRTLS0tyszMVHNzszIyMsL24bZtJsNpbTW30GVn9zvK7+iQrrpK2rPHvJ4yRdqxQ7r44rC1AYhmkeqbjnyGbZvJcE63mlvokvoWgH0N+zT3mbk6cfKEJOmr07+qV7/1qtKTud0OkELvm678Hn03yzK33p1/vnkeMLjW55PeeEO6zIzG17FjHNkDXmFZgVvvzjfP/QrAzEkzte3ubZqYMlGS9N5n73FkD4yCq0Efkuxswh6IUUVTiwh7YIzGf9BLhD0Qwwh7YGyiI+glwh6IYYQ9MHrRE/RS8LC/805+xhKIAcHC/pG3HnG3UUAUiK6gl/qGfW6u9PvfM0UmECN6h/3V512tH8/7sdtNAsa9BLcbMCrdYd/YKF1wgdutAeCgoqlFenfZuzov8zxNSJrgdnOAcS/6jui7ZWcPDPnOTqm21pXmAHDOJZMvGRDyx9qOcc0eCCJ6g76/zk7pjjukK69kgB4QY462HdW88nkM0AOC8E7Q//M/S5s3MxofiDG2bWvJ5iXa27CX0fhAEN4J+pUrufUOiEGWZWn9N9Zz6x0wCO8EPffZAzGL++yBwXkn6CXCHohhhD0QnLeCXiLsgRhG2AMDjeg++szMzEi1I+wmSnpD0izpbNi/84504YXuNgyIUtHU/3WupFJJvrNh//pdrys1MdXtlgGO894RfcAJSfOls0f2eXnS5MkutgiAY45KKlfPkf3Fky5WSkKKu20CXOLZoJdM2OuNN6Rly8zzxIluNwmAU45K2+7eplVXrtK/3fhvirM8Xe6AQUXnFLgjkZ0tPfOM260A4IKiqUUqmlrkdjMAV8XmV9wTJ6QbbmCAHhCDPj76sW5+/mYG6CFmxF7QnzghLVggVVYyGh+IMR8f/VjXbrxWL+9/mdH4iBmxF/SS1NVlnrn1DogpXXaXbNuWxK13iB2xF/QTJ3KfPRCjuM8esSj2gl5iUh0ghhH2iDWxGfQSYQ/EMMIesSR2g14i7IEYRtgjVsR20EvBw37DBnfbBMARwcK+6kCVy60Cwougl/qG/ZIl0rp1brcIgEO6wz7bl621xWu19K+Wut0kIKy8PzNeqLKzpW3bpAkTpMREt1sDwEFFU4u0/wf7NSl1kttNAcKOI/resrIGhvyBA1yzB2JAsJDfcWgH1+wR9Qj6oRw4IF1zzYABerYtNTRItbXmOTD/BgAP+Y99/6EFv1swcICebUsnG6S2WvNMAcA4R9AP5R/+Qaqv7xmN37J7r9atkwoLzS/ezphhngsLzWX9pia3GwwgHL7wf6G/e+Xv1NnVeXY0futn0r510tZCqWKy9PIM87y10Cz3N7ndbCAoy7aH/zra0tKizMxMJ9oTdiH8e4NrbJTmz5f27JEkHbOmaJ69Q/usi/t8ibcs85yaKm3ZIhUXj6HBwAh0983m5mZlZGRE9DOi0Vj6/0dHPtJ1G6/TiZMnJElf9cXp1dwupcdZknq/b6AAJKRKV22RcikAcEao/Z8j+qEERuM3X2BuvZtiH9N2zdNFdt9r9rZtHh0d0qJFUnW1G40FEE49t94lp0mS3uvo0vV1UmtX/y8Ptnl0dkhvL5LqKQAYXwj6YTTFZeuv6t/QhzJhf66OaYfmaaYGDtDr6jKBX1LCaXzAC4pyZmhbbqcmBirleycVCPtgWwcKwLslnMbHuELQD6O8XKrryNZ8hR727e3Sxo1OtxRA2NWUqyjhlLZNU+hh39kuHaIAYPwg6Idg22cnyTuh4GE/SZ8H3Xf9egbjAlHNtqVPTQEoStGAsL+lfog+vp8CgPGDoB/C8ePSwYNn+2t32B9WriTpRd2iBk0esJ9tm/0aG51sLYCwOnVcajuo7oF3RSnSa9OkRJnhd/dknh2I25dt9vNTADA+EPRDaGsbuOxv9SvlqV6StESbBz2il6RW5tkAoldn3wLgt6X/2yidlon+nzcPc9B+mgKA8YGgH0JaWt/XD6hMZfrHnterdV/QI/pu6emRahmAiEs4WwD8tnTrEWnrF+a1z5Iezh7siD4gkQKA8YGgH0JOjlRQYDpz/5B/UI/rp3ow6H6WZfbLznaqpQDCLjlHSisIGvKv5ErXpg62oyWlFUhJFACMDwT9ECxLWr5cyrSbdK9+0bN8qJDvtmLFMN/2AYxvliVduFwfnpReCznkAy6iAGD8IOiHUVoqnZ6QpWutt/SZ8oYN+bg4M0Pe3Xc72EgAkZFfqjnpE1Qx1VJWXCghH2dmyJtBAcD4wc/UDiMry0xru2hRgb7c9YlO2FmDbhsXZ77EV1SY/QBEuaQs6aotuuHtRTrk61JW/FCj7wIF4GsVZj9gnOCIfjAVFZLfL8nMXV9ZKflTs2RZA8/IdS/z+aSqKmnBAhfaCyAs/Gf8enHvi2cX5BZLV1cqKzlV5sa6/qfkA8sSfNI1VdJUCgDGF4I+mLIyM4/t7bf3CfvDh6W1a6X8/L6b5+eb5XV1hDwQzfxn/Lr132/VN//9m1r9x9VnV+QWS4sPS7PWSmn9CkBavlm+uI6Qx7jEr9f1V1Ym/ePZ0fXaskX65jf7vaeZDKe11dxClz3cbTZAhPDrdUMbSf/vDvmtn26VJPkSfNr/g/2anjm9/5uayXBOt5pb6JIoAHBHqP2fa/S99Q/5xx8fEPKS6dM5OeYBIPoFC/lX7nhlYMhLpgAk55gHEAU4dd8tWMg/OPQtdACi32Ahf+2Ma11uGRAeBL1EyAMxipBHLCDoCXkgJhHyiBWxHfTl5YQ8EKPueeUeQh4xIbaDfvFi6YorzN+EPBBTVl65UpNSJxHy8LzYHnWfmSm9/rr00ktmrlsAMePSKZdq+93b1dDeoHkz5rndHCBiYi/oT56UUlLOvs7MJOSBGOA/41e8Fa/4uPieZZdOudTFFgHOiK1T92Vl0pw50vHjbrcEgIO6B959b+v3dKbrjNvNARwVO0f0vUfXf/3r0q5dfY/sAXhS/9H1KfEp+tcb/tXlVgHOiY0j+v630C1dSsgDMSDYLXRLvrTE5VYBzvJ+0HOfPBCb4sV98oA8HvQPSIQ8EIviJd0mQh6Qh4P+AUllvRcQ8kBsCIS8LjIvCXnEuhEFfXNzs2zbHv+Pxx8n5IEwi4b+f6rzlG787Y2EPNCL947obVv6z/88+5qQB2JGy6kW1ZyokUTIA928d3udZUkbN5q///qvCXkghkxKnaTtpdt1w3M3qOzrZYQ8IC8GvSQlJEibNpnQBxBTzplwjnZ/b7cs+j8gySun7jdskPbt67uMTg54nv+MXw/veFht/rY+ywl54KzoD/qyMmnFCmnevIFhD8CzuifDefSdR3X9pusHhD0AI7qDvvdkOEePSm++6W57ADii/4x3H9Z/qP/+y3+73CpgfIreoO8/411ZmfSDH7jXHgCOCDatbeUdlZqdN9vllgHjU3QGfbCQf+AB99oDwBGDhTy/Jw8MLvqCnpAHYhIhD4xOdAU9IQ/EJEIeGL3oCfo//pGQB2LUk398kpAHRil6gn7uXOnRR83fhDwQU1bNWaWFhQsJeWAUomtmvH/6J+m666Q5c9xuCQAHJSckq+K2Cv3XX/5Ls3Jnud0cIKqM7yP62tqBywh5wPP8Z/yqb63vsyw5IZmQB0bB1aC3bamhweR5Q4N53aOsTLr4Yun1191qHoBIsm3pZIPUVmueAwWge+DdVf/vKv1P0/+420bAA1w5dd/UJJWXmynqDx48u7ygQFq+XPrbxjL5fhwYeHfzzWZq2/POc6OpAMLN3yTVlEufbpDaehWAtAL5C/5et/7pTW3982uSpEXPLdLH93ys+Lh4d9oKeIDjQV9dLZWUSO3tA9fV1EhH/3eZfOo1uv6RRwh5wCvqq6V3S6TOgQXA33pQt756n7Z+YV77EnzacP0GQh4YI0dP3VdXS4sWSR0d5ixdn1P1kv6PXabHe4X8p8sYXQ94Rn219PYiqbNDkh14GH5buvWIzoa8JVUWP8LoeiAMHAv6piZzJG/bUlfXwPUPqExlvUL+QatMl73wgJqanGohgIjxN5kjeduW1LcABA35XEvzan5s9gMwJo4FfXm5OV0fSsg/oDL91H5A7e3Sxo1OtRBAxNSUB07XhxLy0rxU22x/iAIAjJUjQW/bZuBdMPfriQEh/4TOnq5fv37gKX4AUcS2zcC7fk4PGvK9NtpPAQDGypGgP37cjK4P1l8PqkCnA2MC+4e8bZv9GhudaCWAiDh1PDC6vm8BSJBUmGj+Dhryss1+fgoAMBaOjLpvaxt8XYVKdLueV75qtFr3B92mtVXKyYlQ4wBEVmfwAmBZ0upJUrIlzU/tH/K9nG6VkikAwGg5EvRpaUOvr1DJkOvT08PYGADOShi8AFiW9JNJw+yfSAEAxsKRU/c5OWYyHMsa2X6WZfbLzo5MuwA4IDlHSiuQNMICIMvsl0QBAMbCkaC3LDPj3WisWDHyLwgAxhHLki4cZQG4iAIAjJVjt9eVlkqpqVJciJ8YF2e2v/vuyLYLgAPyS6WEVIVecuLM9jMoAMBYORb0WVnSli3my/lwYR8XZ7arqDD7AYhySVnSVYECMGzZCRSAr1WY/QCMiaNT4BYXS5WVks9n+nH/M3Ldy3w+qapKWrDAydYBiKjcYunqSinBJ3O9vv8p+cCyBJ90TZU0lQIAhIPjP1NbXCwdPiytXSvl5/ddl59vltfVEfKAJ+UWS4sPS7PWSmn9CkBavlm+uI6QB8LIsu3hp51qaWlRZmammpublZGREbYPt20zGU5rq7mFLjubcTfASESqbzryGbZtJsM53WpuoUuiAAAjEWrfdOX36LtZlrn1jslwgBhkWebWOybDASLK8VP3AADAOQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQAAHkbQAwDgYQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQAAHhbSj9p0/8BdS0tLRBsDYGS6+2QIP0I5avR/YHwKtf+HFPStra2SpOnTp4+xWQAiobW1VZmZmRF7b4n+D4xXw/X/kH6PvqurS/X19UpPT5fF70UD44Zt22ptbVVubq7i4iJzJY7+D4xPofb/kIIeAABEJwbjAQDgYQQ9AAAeRtADAOBhBD0AAB5G0AMA4GEEPQAAHkbQAwDgYf8faKzyfSsCZ7UAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 630x300 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "##============================================##\n",
        "##  Plot some predictions on validation data  ##\n",
        "##============================================##\n",
        "\n",
        "num_print = min([3, len(val_X)])\n",
        "val_Y_predictions = model.predict(val_X[:num_print], verbose=0)\n",
        "for row_idx in range(num_print) :\n",
        "    logger.info(f\"Validationn set row {row_idx} with\")\n",
        "    logger.debug(f\"Y_TRUE =\\n{val_Y[row_idx]}\\n\")\n",
        "    logger.debug(f\"Y_PRED =\\n{val_Y_predictions[row_idx]}\\n\")\n",
        "    print(\"val_Y_predictions[row_idx]\",val_Y_predictions[row_idx])\n",
        "    plot_maps(val_Y[row_idx], val_Y_predictions[row_idx], val_X[row_idx])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
